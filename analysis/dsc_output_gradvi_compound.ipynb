{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "23ebd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import dsc\n",
    "from dsc.query_engine import Query_Processor as dscQP\n",
    "from dsc import dsc_io\n",
    "import pickle\n",
    "\n",
    "from pymir import pd_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pymir import mpl_stylesheet\n",
    "from pymir import mpl_utils\n",
    "\n",
    "import sys\n",
    "sys.path.append('../dsc/functions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8103a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_dfcol(df, colname, value):\n",
    "    return pd_utils.select_dfrows(df, [f\"$({colname}) == {value}\"])\n",
    "\n",
    "def stratify_dfcols(df, condition_list):\n",
    "    for (colname, value) in condition_list:\n",
    "        df = stratify_dfcol(df, colname, value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "891b1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_output = \"/home/saikatbanerjee/scratch/work/gradvi-experiments/linreg_indep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "669c9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/saikatbanerjee/scratch/work/gradvi-experiments/linreg_indep/linreg_indep.db\n"
     ]
    }
   ],
   "source": [
    "db = os.path.join(dsc_output, os.path.basename(os.path.normpath(dsc_output)) + \".db\")\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6bbe2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Target can be any module name, group name\n",
    "or module.variable\n",
    "There are two groups of methods, one of them \n",
    "needs to be force removed during query (groups = [\"fit_cpt:\"])\n",
    "'''\n",
    "\n",
    "target = [\"simulate\", \"simulate.sfix\", \"simulate.pve\", \"fit\", \"mse.err\", \"simulate.se\", \"coef_mse.err\"]\n",
    "#condition = [\"simulate.sfix == 2\", \"simulate.signal == 'normal'\", \"simulate.dims == '(50, 200)'\"]\n",
    "#groups = [\"fit_cpt:\"]\n",
    "condition = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5a84a901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DSC</th>\n",
       "      <th>simulate</th>\n",
       "      <th>simulate.sfix</th>\n",
       "      <th>simulate.se:output</th>\n",
       "      <th>simulate.pve</th>\n",
       "      <th>simulate.output.file</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit.output.file</th>\n",
       "      <th>mse.err:output</th>\n",
       "      <th>coef_mse.err:output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_6</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_6_gradvi_compound_1</td>\n",
       "      <td>mse/equicorrgauss_6_gradvi_compound_1_predict_...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>2</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_21</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_21</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_21_gradvi_compou...</td>\n",
       "      <td>mse/equicorrgauss_21_gradvi_compound_1_predict...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>3</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_36</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_36</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_36_gradvi_compou...</td>\n",
       "      <td>mse/equicorrgauss_36_gradvi_compound_1_predict...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>4</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_51</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_51</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_51_gradvi_compou...</td>\n",
       "      <td>mse/equicorrgauss_51_gradvi_compound_1_predict...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>5</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_66</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_66</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_66_gradvi_compou...</td>\n",
       "      <td>mse/equicorrgauss_66_gradvi_compound_1_predict...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>6</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_81</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_81</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_81_gradvi_compou...</td>\n",
       "      <td>mse/equicorrgauss_81_gradvi_compound_1_predict...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>7</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_96</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_96</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_96_gradvi_compou...</td>\n",
       "      <td>mse/equicorrgauss_96_gradvi_compound_1_predict...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>8</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_111</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_111</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_111_gradvi_compo...</td>\n",
       "      <td>mse/equicorrgauss_111_gradvi_compound_1_predic...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>9</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_126</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_126</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_126_gradvi_compo...</td>\n",
       "      <td>mse/equicorrgauss_126_gradvi_compound_1_predic...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>10</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_141</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_141</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_141_gradvi_compo...</td>\n",
       "      <td>mse/equicorrgauss_141_gradvi_compound_1_predic...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_6</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_6_gradvi_compound_1</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_6_gradvi_compound_1_coe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>2</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_21</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_21</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_21_gradvi_compou...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_21_gradvi_compound_1_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>3</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_36</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_36</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_36_gradvi_compou...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_36_gradvi_compound_1_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>4</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_51</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_51</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_51_gradvi_compou...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_51_gradvi_compound_1_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>5</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_66</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_66</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_66_gradvi_compou...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_66_gradvi_compound_1_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>6</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_81</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_81</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_81_gradvi_compou...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_81_gradvi_compound_1_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>7</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_96</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_96</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_96_gradvi_compou...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_96_gradvi_compound_1_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>8</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_111</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_111</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_111_gradvi_compo...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_111_gradvi_compound_1_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>9</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_126</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_126</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_126_gradvi_compo...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_126_gradvi_compound_1_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>10</td>\n",
       "      <td>equicorrgauss</td>\n",
       "      <td>1</td>\n",
       "      <td>equicorrgauss/equicorrgauss_141</td>\n",
       "      <td>0.6</td>\n",
       "      <td>equicorrgauss/equicorrgauss_141</td>\n",
       "      <td>gradvi_compound</td>\n",
       "      <td>gradvi_compound/equicorrgauss_141_gradvi_compo...</td>\n",
       "      <td>NA</td>\n",
       "      <td>coef_mse/equicorrgauss_141_gradvi_compound_1_c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DSC       simulate  simulate.sfix               simulate.se:output  \\\n",
       "2405    1  equicorrgauss              1    equicorrgauss/equicorrgauss_6   \n",
       "2420    2  equicorrgauss              1   equicorrgauss/equicorrgauss_21   \n",
       "2435    3  equicorrgauss              1   equicorrgauss/equicorrgauss_36   \n",
       "2450    4  equicorrgauss              1   equicorrgauss/equicorrgauss_51   \n",
       "2465    5  equicorrgauss              1   equicorrgauss/equicorrgauss_66   \n",
       "2480    6  equicorrgauss              1   equicorrgauss/equicorrgauss_81   \n",
       "2495    7  equicorrgauss              1   equicorrgauss/equicorrgauss_96   \n",
       "2510    8  equicorrgauss              1  equicorrgauss/equicorrgauss_111   \n",
       "2525    9  equicorrgauss              1  equicorrgauss/equicorrgauss_126   \n",
       "2540   10  equicorrgauss              1  equicorrgauss/equicorrgauss_141   \n",
       "2555    1  equicorrgauss              1    equicorrgauss/equicorrgauss_6   \n",
       "2570    2  equicorrgauss              1   equicorrgauss/equicorrgauss_21   \n",
       "2585    3  equicorrgauss              1   equicorrgauss/equicorrgauss_36   \n",
       "2600    4  equicorrgauss              1   equicorrgauss/equicorrgauss_51   \n",
       "2615    5  equicorrgauss              1   equicorrgauss/equicorrgauss_66   \n",
       "2630    6  equicorrgauss              1   equicorrgauss/equicorrgauss_81   \n",
       "2645    7  equicorrgauss              1   equicorrgauss/equicorrgauss_96   \n",
       "2660    8  equicorrgauss              1  equicorrgauss/equicorrgauss_111   \n",
       "2675    9  equicorrgauss              1  equicorrgauss/equicorrgauss_126   \n",
       "2690   10  equicorrgauss              1  equicorrgauss/equicorrgauss_141   \n",
       "\n",
       "      simulate.pve             simulate.output.file              fit  \\\n",
       "2405           0.6    equicorrgauss/equicorrgauss_6  gradvi_compound   \n",
       "2420           0.6   equicorrgauss/equicorrgauss_21  gradvi_compound   \n",
       "2435           0.6   equicorrgauss/equicorrgauss_36  gradvi_compound   \n",
       "2450           0.6   equicorrgauss/equicorrgauss_51  gradvi_compound   \n",
       "2465           0.6   equicorrgauss/equicorrgauss_66  gradvi_compound   \n",
       "2480           0.6   equicorrgauss/equicorrgauss_81  gradvi_compound   \n",
       "2495           0.6   equicorrgauss/equicorrgauss_96  gradvi_compound   \n",
       "2510           0.6  equicorrgauss/equicorrgauss_111  gradvi_compound   \n",
       "2525           0.6  equicorrgauss/equicorrgauss_126  gradvi_compound   \n",
       "2540           0.6  equicorrgauss/equicorrgauss_141  gradvi_compound   \n",
       "2555           0.6    equicorrgauss/equicorrgauss_6  gradvi_compound   \n",
       "2570           0.6   equicorrgauss/equicorrgauss_21  gradvi_compound   \n",
       "2585           0.6   equicorrgauss/equicorrgauss_36  gradvi_compound   \n",
       "2600           0.6   equicorrgauss/equicorrgauss_51  gradvi_compound   \n",
       "2615           0.6   equicorrgauss/equicorrgauss_66  gradvi_compound   \n",
       "2630           0.6   equicorrgauss/equicorrgauss_81  gradvi_compound   \n",
       "2645           0.6   equicorrgauss/equicorrgauss_96  gradvi_compound   \n",
       "2660           0.6  equicorrgauss/equicorrgauss_111  gradvi_compound   \n",
       "2675           0.6  equicorrgauss/equicorrgauss_126  gradvi_compound   \n",
       "2690           0.6  equicorrgauss/equicorrgauss_141  gradvi_compound   \n",
       "\n",
       "                                        fit.output.file  \\\n",
       "2405  gradvi_compound/equicorrgauss_6_gradvi_compound_1   \n",
       "2420  gradvi_compound/equicorrgauss_21_gradvi_compou...   \n",
       "2435  gradvi_compound/equicorrgauss_36_gradvi_compou...   \n",
       "2450  gradvi_compound/equicorrgauss_51_gradvi_compou...   \n",
       "2465  gradvi_compound/equicorrgauss_66_gradvi_compou...   \n",
       "2480  gradvi_compound/equicorrgauss_81_gradvi_compou...   \n",
       "2495  gradvi_compound/equicorrgauss_96_gradvi_compou...   \n",
       "2510  gradvi_compound/equicorrgauss_111_gradvi_compo...   \n",
       "2525  gradvi_compound/equicorrgauss_126_gradvi_compo...   \n",
       "2540  gradvi_compound/equicorrgauss_141_gradvi_compo...   \n",
       "2555  gradvi_compound/equicorrgauss_6_gradvi_compound_1   \n",
       "2570  gradvi_compound/equicorrgauss_21_gradvi_compou...   \n",
       "2585  gradvi_compound/equicorrgauss_36_gradvi_compou...   \n",
       "2600  gradvi_compound/equicorrgauss_51_gradvi_compou...   \n",
       "2615  gradvi_compound/equicorrgauss_66_gradvi_compou...   \n",
       "2630  gradvi_compound/equicorrgauss_81_gradvi_compou...   \n",
       "2645  gradvi_compound/equicorrgauss_96_gradvi_compou...   \n",
       "2660  gradvi_compound/equicorrgauss_111_gradvi_compo...   \n",
       "2675  gradvi_compound/equicorrgauss_126_gradvi_compo...   \n",
       "2690  gradvi_compound/equicorrgauss_141_gradvi_compo...   \n",
       "\n",
       "                                         mse.err:output  \\\n",
       "2405  mse/equicorrgauss_6_gradvi_compound_1_predict_...   \n",
       "2420  mse/equicorrgauss_21_gradvi_compound_1_predict...   \n",
       "2435  mse/equicorrgauss_36_gradvi_compound_1_predict...   \n",
       "2450  mse/equicorrgauss_51_gradvi_compound_1_predict...   \n",
       "2465  mse/equicorrgauss_66_gradvi_compound_1_predict...   \n",
       "2480  mse/equicorrgauss_81_gradvi_compound_1_predict...   \n",
       "2495  mse/equicorrgauss_96_gradvi_compound_1_predict...   \n",
       "2510  mse/equicorrgauss_111_gradvi_compound_1_predic...   \n",
       "2525  mse/equicorrgauss_126_gradvi_compound_1_predic...   \n",
       "2540  mse/equicorrgauss_141_gradvi_compound_1_predic...   \n",
       "2555                                                 NA   \n",
       "2570                                                 NA   \n",
       "2585                                                 NA   \n",
       "2600                                                 NA   \n",
       "2615                                                 NA   \n",
       "2630                                                 NA   \n",
       "2645                                                 NA   \n",
       "2660                                                 NA   \n",
       "2675                                                 NA   \n",
       "2690                                                 NA   \n",
       "\n",
       "                                    coef_mse.err:output  \n",
       "2405                                                 NA  \n",
       "2420                                                 NA  \n",
       "2435                                                 NA  \n",
       "2450                                                 NA  \n",
       "2465                                                 NA  \n",
       "2480                                                 NA  \n",
       "2495                                                 NA  \n",
       "2510                                                 NA  \n",
       "2525                                                 NA  \n",
       "2540                                                 NA  \n",
       "2555  coef_mse/equicorrgauss_6_gradvi_compound_1_coe...  \n",
       "2570  coef_mse/equicorrgauss_21_gradvi_compound_1_co...  \n",
       "2585  coef_mse/equicorrgauss_36_gradvi_compound_1_co...  \n",
       "2600  coef_mse/equicorrgauss_51_gradvi_compound_1_co...  \n",
       "2615  coef_mse/equicorrgauss_66_gradvi_compound_1_co...  \n",
       "2630  coef_mse/equicorrgauss_81_gradvi_compound_1_co...  \n",
       "2645  coef_mse/equicorrgauss_96_gradvi_compound_1_co...  \n",
       "2660  coef_mse/equicorrgauss_111_gradvi_compound_1_c...  \n",
       "2675  coef_mse/equicorrgauss_126_gradvi_compound_1_c...  \n",
       "2690  coef_mse/equicorrgauss_141_gradvi_compound_1_c...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp = dscQP(db, target, condition)\n",
    "qp_df = qp.output_table\n",
    "#qp_df\n",
    "df_gv   = stratify_dfcols(qp_df, [('simulate.sfix', 1), (\"simulate.pve\", 0.6), ('fit', 'gradvi_compound')])\n",
    "df_cavi = stratify_dfcols(qp_df, [('simulate.sfix', 1), (\"simulate.pve\", 0.6), ('fit', 'mr_ash')])\n",
    "\n",
    "df_gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c103db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c3f76882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gradvi_compound/equicorrgauss_21_gradvi_compound_1'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gv['fit.output.file'].iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bafb35ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'equicorrgauss/equicorrgauss_21'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gv['simulate.output.file'].iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3c915e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mse/equicorrgauss_21_gradvi_compound_1_predict_linear_1_mse_1'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gv['mse.err:output'].iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a958ed9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006417003110395274"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cavi['fit.output.file'].iloc[idx]\n",
    "\n",
    "mse_gv = dsc_io.load_dsc(os.path.join(dsc_output, f\"{df_gv['mse.err:output'].iloc[idx]}.rds\"))\n",
    "\n",
    "mse_gv['err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "501191dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_resfile = os.path.join(dsc_output, f\"{df_gv['fit.output.file'].iloc[idx]}.pkl\")\n",
    "res = dsc_io.load_dsc(_resfile)\n",
    "\n",
    "_resfile_cavi = os.path.join(dsc_output, f\"{df_cavi['fit.output.file'].iloc[idx]}.rds\")\n",
    "res_cavi = dsc_io.load_dsc(_resfile_cavi)\n",
    "    \n",
    "_datafile = os.path.join(dsc_output, f\"{df_gv['simulate.output.file'].iloc[idx]}.pkl\")\n",
    "data = dsc_io.load_dsc(_datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1fb535bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.47594726e-09, -7.22650488e-09,  2.03669351e-10, ...,\n",
       "        8.80410184e-09,  6.38169391e-10, -4.35792412e-09])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['beta_est']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "98edba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.37132216e-05],\n",
       "       [-2.25920798e-05],\n",
       "       [ 7.68126484e-05],\n",
       "       ...,\n",
       "       [ 8.01438893e-05],\n",
       "       [ 1.45644518e-05],\n",
       "       [ 8.17674693e-06]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cavi['beta_est']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f4fc26a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.37132216e-05, -2.25920798e-05,  7.68126484e-05, ...,\n",
       "        8.01438893e-05,  1.45644518e-05,  8.17674693e-06])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(res_cavi['beta_est'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3cdcd330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkO0lEQVR4nO3deXBU55nv8e+D1FJrQexgsFiEDMbgBQtB8DhgNoklDosTxzBTYxL7Xk9yHcdO1XiGjKcy3FuZuU6cGme5rsQ4cYwTxwxeWDJ2DEhgG28ZBDaYHcyAERIgNrFpRe/9Qy1ZCO3draPu/n2qurr7nPc95zkI9aP3vKefY845REQkdnXzOgAREfGWEoGISIxTIhARiXFKBCIiMU6JQEQkxsV7HUBH9O3b1w0bNszrMEREIsrWrVtPOef6NV4ekYlg2LBhFBQUeB2GiEhEMbMjTS3XqSERkRinRCAiEuOUCEREYlxEzhE0paqqisLCQsrLy70Opcvw+/2kp6fj8/m8DkVEurCoSQSFhYV0796dYcOGYWZeh+M55xynT5+msLCQjIwMr8MRkS4sak4NlZeX06dPHyWBADOjT58+GiGJSKuiJhEASgKN6N9DRNoiqhKBiEi0unz5MhcvXgzLtpUIQujEiRP89V//NcOHD2fcuHHccccdrFq1qsPbW7p0KT/96U954YUXWLRo0VXrTp06Rb9+/aioqGDKlCn6gp1IlPvzn//MG2+8EZZtKxGEiHOO+fPnM3nyZA4dOsTWrVtZsWIFhYWFV7Wrrq5u97bvueceNmzYwOXLl+uXvfrqq8ydO5fExMSgYxeRrunChQuUlZUBMH36dKZMmRKW/cRsIlj98THufHIjGUve4M4nN7L642NBbW/jxo0kJCTw7W9/u37Z0KFDeeSRR3jhhRe49957+epXv0pubi4XL15k+vTpZGVlccstt7BmzZr6Pv/6r//KjTfeyIwZM9i3bx8AaWlpTJ48mT/96U/17VasWHHNKEFEokdFRQW//vWv2bBhAwA9e/ZkwIABYdlX1Fw+2h6rPz7GD17/lLKqKwAcO1fGD17/FID5t1/foW3u2rWLrKysZtd/+OGH7Nixg969e1NdXc2qVatIS0vj1KlTTJw4kblz57Jt2zZWrFjBxx9/THV1NVlZWYwbNw6ARYsW8cc//pH77ruPoqIi9u/fz9SpUzsUq4h0XRUVFSQmJpKYmEhOTg6DBw8O+z5jckTw1Lp99UmgTlnVFZ5aty9k+3j44Ye57bbbGD9+PAA5OTn07t0bqD2N9E//9E/ceuutzJgxg2PHjnHixAk2b97MggULSE5OJi0tjblz59Zv7+677+a9997j/PnzrFy5kq9//evExcWFLF4R8d5nn33G008/TXFxMQBjx46lT58+Yd9vTCaConNl7VreFmPGjGHbtm3175955hny8/MpKSkBICUlpX7dSy+9RElJCVu3buWTTz5hwIAB9df7N3fJZ1JSErNmzWLVqlU6LSQSZZxzAAwaNIhRo0aRnJzcqfsPSSIws1lmts/MDprZkibWm5n9IrB+h5lltbVvOAzqmdSu5W0xbdo0ysvL+dWvflW/rOHkbkOlpaX0798fn8/Hpk2bOHKktjLs5MmTWbVqFWVlZVy4cOGqOQGoPT307//+75w4cYKJEyd2OFYR8UbND3vg/uWLR80Pe/Dhhx/yxz/+EeccSUlJzJ8/nx49enRqXEEnAjOLA54BZgOjgUVmNrpRs9nAiMDjIeBX7egbco/PvJEk39WnVZJ8cTw+88YOb9PMWL16Ne+88w4ZGRlMmDCBxYsX8+Mf//iatn/zN39DQUEB2dnZvPTSS4waNQqArKws7rvvPsaOHcvXvvY1Jk2adFW/3NxcioqKuO+++/RlMZEIU/PDHphxzSP+rcfx+/0duqIwVKxuSNLhDZjdASx1zs0MvP8BgHPu/zZo8yzwtnPu5cD7fcAUYFhrfZuSnZ3tGl83v2fPHm666aY2x73642M8tW4fRefKGNQzicdn3tjhieKurL3/LiISHu5fahNBNXFs4q8YSiEj+W9qHHT736WdEoOZbXXOZTdeHoqrhq4HjjZ4Xwh8qQ1trm9jXwDM7CFqRxMMGTIkuIipvTooGj/4RaRrMxwHGUYcVxjJf9MVxvahmCNo6jgaDzOaa9OWvrULnVvmnMt2zmX363fNLTdFRLqs8vJy3rY7qCaOOGr4H7zMND7wOqx6oUgEhUDDC13TgaI2tmlLXxGRiFZYWMhmvsThwMedD+/mA5oSikSwBRhhZhlmlgAsBNY2arMWuD9w9dBEoNQ5V9zGviIiEefy5cscOnQIgBtuuIFH+B2Z7vBVbZyrnTD2WtCJwDlXDXwXWAfsAVY653aZ2bfNrK7ewpvAIeAg8Bzwv1rqG2xMIiJee/PNN3n11VeprKwEoNfSz6/50DcDlnbORHFLQlJiwjn3JrUf9g2X/brBawc83Na+IiKR6Pz58/h8PpKSkpgxYwYVFRUkJCR80aALfOg3JSa/WRwux48fZ+HChWRmZjJ69GjmzJnD/v37AXj66afx+/2Ultb+R/jmN7/Js88+e1X/1atXM2fOHABSU1M7N3gRCUpnFokLNSWCEHHOsWDBAqZMmcJnn33G7t27+bd/+zdOnDgBwMsvv8z48ePr70+waNEiVqxYcdU2VDpCJPLUlYdJTEwkNzeXL3/5yx5H1H6xmwh2rISnb4alPWufd6wManObNm3C5/NdVYZ67NixTJo0ic8++4yLFy/yox/9iJdffhmAGTNmsHfv3vriUpcvXyYvL4/58+cHFYeIdJ66InFFRbUXO44dO7a+uGQkic1EsGMl/Ol7UHoUcLXPf/peUMlg586d9SWjG3v55ZdZtGgRkyZNYt++fZw8eZK4uDjuueceVq6s3efatWuZOnUq3bt373AMItI56ioyXH/99YwePTriT+XGZiLI/z9Q1ajSaFVZ7fIwWLFiBQsXLqRbt27cc889vPLKK8DVp4d0WkgkMrz//vu89NJLOOfw+/3MmzePtLQ0r8MKSkzemIbSwvYtb4MxY8bw6quvXrN8x44dHDhwgJycHAAqKysZPnw4Dz/8MHfeeSfFxcVs376dDz744Jo5AxHpevx+PykpKVRXV+Pz+bwOJyRic0TQI719y9tg2rRpVFRU8Nxzz9Uv27JlC48++ihLly7l8OHDHD58mKKiIo4dO8aRI0cwM77xjW+wePFi5syZg9/v7/D+RSQ8qqurWb9+ff2tY7OysliwYEHUJAGI1UQw/Yfga3TvAV9S7fIOMjNWrVrFhg0byMzMZMyYMSxdupS3336bBQsWXNV2wYIF9X/9L1q0iO3bt7Nw4cIO71tEwsfMOHToUP2EcDSWgA+6DLUXQlGGmh0ra+cESgtrRwLTfwi3fiPEkXpPZahF2q+8vJwPP/yQSZMmER8fT1VVVVSMAMJZhjoy3fqNqPzgF5HgFRYWsnnzZoYMGUJmZmZUJIGWxOapIRGRRi5dusRnn30GBIrEPfIImZmZHkfVOaIqEUTiaa5w0r+HSNu99dZbvPbaa18UievVy+OIOk/UnBry+/2cPn2aPn36ROVkTns55zh9+rSuRBJpQWlpKQkJCfVF4iZPnnx1kbgYETWJID09ncLCQkpKSrwOpcvw+/2kp3f8kliRaFZRUcGzzz7LqFGjmDt3Lj169PA6JM9ETSLw+XxkZGR4HYaIdHHl5eX4/X4SExOZOXNmSO6BHumiao5ARKQlBw8evKpI3G233RZTcwHNUSIQkahXd+FEeno6Y8aMUXHHRpQIRCSqvffee1cViZs7d64SQSNKBCIS1ZKSkkhNTaW6utrrULqsqJksFhEBqKqqIj8/n4yMDG688UbGjRvX7L1CpJZGBCISVbp168aRI0fq7/4nrdOIQEQiXllZGR988AF33XUX8fHxPPjgg8TH6+OtrTQiEJGIV1RUxPvvv8+RI0cAlATaSYlARCLSxYsXOXjwIACZmZl873vfi5kicaGmRCAiEemtt97i9ddfry8S17NnT28DimAaP4lIxDh37hwJCQkkJyeTk5NDVVVVTBaJCzWNCEQkItQVicvLywOgR48e9O3b1+OoooNGBCLSpZWVlZGUlERiYiKzZ89WkbgwCGpEYGa9zWyDmR0IPDdZvcnMZpnZPjM7aGZLGix/ysz2mtkOM1tlZj2DiUdEoktdkbhjx44BcOutt2ouIAyCPTW0BMh3zo0A8gPvr2JmccAzwGxgNLDIzEYHVm8AbnbO3QrsB34QZDwiEgVqamqA2iJxt956a0zfK6AzBJsI5gHLA6+XA/ObaDMBOOicO+ScqwRWBPrhnFvvnKsrAPIRoLuoiMS4zZs3X1Uk7u677yY1NdXrsKJasIlggHOuGCDw3L+JNtcDRxu8Lwwsa+wB4M/N7cjMHjKzAjMr0F3IRKJXSkoKaWlpKhLXiVqdLDazPOC6JlY90cZ9NHUD4avuqm5mTwDVwEvNbcQ5twxYBpCdna27sotEiaqqKvLy8sjIyGDUqFFkZWWRlZXldVgxpdVE4Jyb0dw6MzthZgOdc8VmNhA42USzQmBwg/fpQFGDbSwG7gamu7q7R4hIzOjWrRuff/45ycnJjBo1yutwYlKwp4bWAosDrxcDa5poswUYYWYZZpYALAz0w8xmAf8IzHXOXQ4yFhGJEGVlZeTl5VFdXU1cXBwPPvggd911l9dhxaxgE8GTQI6ZHQByAu8xs0Fm9iZAYDL4u8A6YA+w0jm3K9D//wHdgQ1m9omZ/TrIeEQkAhQVFfHhhx+qSFwXYZF4NiY7O9sVFBR4HYaItMOFCxc4fvw4I0aMAKC0tFSXhXYyM9vqnMtuvFwlJkSkU6xbt45Vq1ZRVVUFoCTQhWg8JiJh07BIXG5uLlVVVfh8Pq/DkkY0IhCRsGhcJC4tLY0+ffp4HJU0RSMCEQmpy5cvk5ycTGJiInPmzFGRuAigEYGIhMyBAwf42c9+Vl8k7pZbbtFcQARQIhCRoNUViRs8eLCKxEUgJQIRCcq7777LH/7wBxWJi2BKBCISlO7du9OzZ08ViYtgmiwWkXapqqpi/fr1ZGZmMmrUKG6//XZuv/12r8OSIGhEICLt0q1bN44dO8bJk03VmJRIpBGBiLTq8uXLvP/++0ydOpX4+HgefPBB4uLivA5LQkQjAhFp1fHjx/noo4/4/PPPAZQEoowSgYg06cKFC+zfvx+A4cOH8+ijjzJ8+HCPo5JwUCIQkSatW7eONWvW1BeJS0tL8zgiCRfNEYhIvbNnz5KYmKgicTFGIwIRAaC8vJxly5apSFwM0ohAJMZdunSJlJQU/H4/X/nKV1QkLgZpRCASw+qKxBUWFgJw8803ay4gBikRiMSguiJxQ4YM4fbbb6dXr14eRyReUiIQiTHvvPMOv//973HO1d8zICUlxeuwxENKBCIxJi0tjd69e6tInNTTZLFIlKuqqmLdunVkZmZy0003qUicXEOJQCTKdevWjeLiYt0sRpqlRCAShS5dusR7773HtGnT8Pl8PPDAA6oPJM3SHIFIFDpx4gRbtmzh6NGjgIrEScuUCESixPnz59m3bx+gInHSPkoEIlFi/fr1rF27tr5IXPfu3T2OSCKF5ghEItiZM2fw+/31ReKuXLmiInHSbkGNCMyst5ltMLMDgecmv55oZrPMbJ+ZHTSzJU2s/3szc2bWN5h4RGJJU0Xi9A1h6YhgTw0tAfKdcyOA/MD7q5hZHPAMMBsYDSwys9EN1g8GcoDPg4xFJCZcunQJAL/fz1e/+lWmTJnibUAS8YJNBPOA5YHXy4H5TbSZABx0zh1yzlUCKwL96jwN/APggoxFJOrt37+fp59+ur5I3JgxY1QkToIWbCIY4JwrBgg892+izfXA0QbvCwPLMLO5wDHn3PbWdmRmD5lZgZkVlJSUBBm2SGSpKxI3dOhQxo0bR+/evT2OSKJJq5PFZpYHXNfEqifauA9rYpkzs+TANnLbshHn3DJgGUB2drZGDxIz3n77bY4cOcL9999PYmIis2fP9jokiTKtJgLn3Izm1pnZCTMb6JwrNrOBwMkmmhUCgxu8TweKgEwgA9huZnXLt5nZBOfc8XYcg0hU69mzJ5cuXeLKlSvEx+tCPwm9YE8NrQUWB14vBtY00WYLMMLMMswsAVgIrHXOfeqc6++cG+acG0ZtwshSEpBYV1lZydq1a9m9ezcAY8eO5Stf+YqSgIRNsIngSSDHzA5Qe+XPkwBmNsjM3gRwzlUD3wXWAXuAlc65XUHuVyRqxcfHc/LkSc6cOeN1KBIjzLnIO92enZ3tCgoKvA5DJGQaF4m7cuWK6gNJyJnZVudcduPlKjEh0gXUFYmruyxUSUA6kxKBiEdKS0vZu3cv8EWRuIyMDI+jklik2ScRj+Tl5XHo0CEyMzPx+XwqEieeUSIQ6USnT5/G7/eTkpJCbm4u1dXVKhInntOpIZFOUl5eznPPPUd+fj5QWyZaReKkK9CIQCTMLl68SGpqKn6/n7lz5zJ48ODWO4l0Io0IRMJo//79/OxnP6u/ZeTo0aM1FyBdjhKBSBhcuXIFqC0Sl52dTd++utWGdF1KBCIhtmnTJn7/+9/jnCMxMZFZs2aRlJTkdVgizdIcgUiI9erVi7KyMhWJk4ihEYFIkCorK1mzZs1VReLmzJmjJCARQ4lAJEjx8fGUlJRw9uxZr0MR6RD9ySLSARcvXmTz5s3MmDEDn8/HAw88QLdu+rtKIpP+54p0QElJCdu2basvEqckIJFM/3tF2ujcuXPs2bMHgIyMDBWJk6ihU0MibZSXl8fhw4e54YYb8Pl8pKameh2SSEgoEYi04NSpUyQlJZGSksLMmTO5cuWKisRJ1NGpIZFmlJeX85vf/OaqInE9e/b0NiiRMNCIQKSRCxcu0L17d/x+P/PmzVOROIl6GhGINLBv3z5+/vOf1xeJu+mmmzQXIFFPiUCEL4rEDRs2jAkTJqhInMQUJQKJeRs3buTFF1+sLxKXm5urInESUzRHIDGvT58+VFRUqEicxCyNCCTmVFZWsnr1anbt2gXAbbfdxuzZs5UEJGYpEUjMiY+P5/Tp05SWlnodikiXoD+BJCZcuHCBzZs3k5OTg8/n41vf+pbqA4kE6DdBYsKpU6f4+OOPOXbsGKAicSIN6bdBolbjInGPPfYYw4YN8zYokS4oqERgZr3NbIOZHQg892qm3Swz22dmB81sSaN1jwTW7TKznwQTj0hD+fn5vPHGG1RVVQGQkpLicUQiXVOwcwRLgHzn3JOBD/glwD82bGBmccAzQA5QCGwxs7XOud1mNhWYB9zqnKsws/5BxiMxrqSkhOTkZFJSUsjNzaWmpkZF4kRaEeypoXnA8sDr5cD8JtpMAA465w455yqBFYF+AN8BnnTOVQA4504GGY/EsKaKxPXo0cPjqES6vmATwQDnXDFA4Lmpv+ivB442eF8YWAYwEphkZn8xs3fMbHyQ8UgMOn/+PAB+v58FCxYwffp0jyMSiSytJgIzyzOznU085rXWt24TTSxzged4oBcwEXgcWGlmTbXHzB4yswIzKygpKWnjriXaNS4SN2rUKM0FiLRTq3MEzrkZza0zsxNmNtA5V2xmA4GmTu0UAg3r+KYDRQ3Wve6cc8B/mVkN0Be45pPeObcMWAaQnZ3tGq+X2HLlyhXi4uLIyMhg4sSJ9OvXz+uQRCJWsKeG1gKLA68XA2uaaLMFGGFmGWaWACwM9ANYDUwDMLORQAJwKsiYJMrl5+fz4osvUlNTQ0JCAjk5Ofj9fq/DEolYwSaCJ4EcMztA7VVBTwKY2SAzexPAOVcNfBdYB+wBVjrndgX6Pw8MN7Od1E4iLw6MDkSa1a9fPwYOHEhNTY3XoYhEBYvEz93s7GxXUFDgdRjSSSorK3njjTcYOXIkY8aM8TockYhlZludc9mNl+ubxdLlxcfHc/bs2fqrg0QktJQIpEu6cOFC/beCu3Xrxje/+U3uuOMOr8MSiUpKBNIlnT59mu3bt6tInEgn0G+XdBlnzpxh9+7dQO29g1UkTqRz6H4E0mVs3LiRw4cPM2LECHw+H8nJyV6HJBITlAjEUydPniQ5OZnU1FRmzZqlInEiHtCpIfFMeXk5v/3tb9m4cSMAqamppKWleRyVSOzRiEA6XWlpKT169KgvEjd48ODWO4lI2GhEIJ1q7969/OIXv+Dzzz8HVCROpCtQIpBOUV1dDcDw4cO544476N9f9yAS6SqUCCTs8vLyrioSN2PGDBWJE+lCNEcgYTdgwABqamqoqanRF8NEuiD9VkrIVVRU8Nprr7Fz504AbrnlFnJzc4mP198dIl2REoGEnM/n4/z581y8eNHrUESkDZQIJCTOnz/Pf/7nf9YXiVu8eDETJ070OiwRaQMlAgmJM2fOsGPHDhWJE4lA+m2VDjtz5gy7dtXebE5F4kQil2bvpMM2bdrE4cOHGTlypIrEiUQwJQJplxMnTpCSkkJqaiozZ87EOacicSIRTqeGpM3Ky8t5/vnnyc/PB2qLxHXv3t3jqEQkWBoRSKvOnTtHz5498fv9fO1rXyM9Pd3rkEQkhDQikBY1LhI3cuRIzQWIRBklAmlSwyJxd955JwMGDPA4IhEJFyUCucaGDRtYvnx5fZG46dOnk5iY6HVYIhImmiOQa1x33XUAKhInEiP0Wy5UVFTw6quv8umnnwK1ReJycnJUJE4kRigRCD6fj4sXL3L58mWvQxERDygRxKjS0lLWrl1LZWVlfZG4L33pS16HJSIeCCoRmFlvM9tgZgcCz72aaTfLzPaZ2UEzW9Jg+Vgz+8jMPjGzAjObEEw80nbnzp1j165dFBcXA2BmHkckIl4JdkSwBMh3zo0A8gPvr2JmccAzwGxgNLDIzEYHVv8E+N/OubHADwPvJUxOnz5df7OYoUOH8thjjzF06FCPoxIRrwWbCOYBywOvlwPzm2gzATjonDvknKsEVgT6ATggLfC6B1AUZDzSgk2bNrFu3TqqqqoASEpK8jgiEekKgr0sZIBzrhjAOVdsZv2baHM9cLTB+0Kg7mT0Y8A6M/sptUnpr4KMRxo5fvw4qamppKamMmvWLBWJE5FrtDoiMLM8M9vZxGNea33rNtHEMhd4/g7wfefcYOD7wG9biOOhwDxCQUlJSRt3HdvKy8v53e9+x8aNGwEViRORprU6InDOzWhunZmdMLOBgdHAQOBkE80KgcEN3qfzxSmgxcCjgdevAL9pIY5lwDKA7Oxs11w7ubZI3ODBg1vvJCIxK9g5grXUfpgTeF7TRJstwAgzyzCzBGBhoB/UJoS7Aq+nAQeCjCfm7dmz55oicZoLEJGWBDtH8CSw0sweBD4H7gUws0HAb5xzc5xz1Wb2XWAdEAc875zbFej/P4Gfm1k8UA48FGQ8Mauqqgqfz0dmZiaTJk1SkTgRaTNzLvLOsmRnZ7uCggKvw+gy1q9fz9GjR/nWt76l2kAi0iwz2+qcy268XMVkIphzDjNj0KBBxMXFEYlJXUS8pz8fI1BFRQWvvPJK/ZfDbr75ZqZPn05cXJzHkYlIJFIiiEA+n49Lly5RVlbmdSgiEgWUCCLEuXPnWLNmzVVF4iZMUGkmEQmeEkGEKC0tZffu3SoSJyIhp0TQhZ06dar+ZjFDhw7l+9//vorEiUjIKRF0Ye+88w4bNmyoLxLn9/s9jkhEopEuH+1iiouL62sCqUiciHQGjQhasWXtsxxfegM1/9KD40tvYMvaZ8O2r/Lycl544QU2bdoEQEpKCqmpqWHbn4gIaETQoi1rn+Xmrf9MklWCwXWU0GPrP7MFGD/370K2n7Nnz9KrVy/8fj9f//rXSU9PD9m2RURaoxFBCwZve6o2CTSQZJUM3vZUyPaxZ88efvnLX9YXiRsxYoSKxIlIp1IiaEF/1/R9D/q7U0Fvu24CODMzk8mTJ3PdddcFvU0RkY5QImjBSevXzPK+QW133bp1LF++nJqaGhISEpgyZQoJCQlBbVNEpKOUCFpwNOtxytzVH9BlLoGjWY+3e1vOufqicOnp6QwfPlxF4kSkS1AiaMH4uX/HznE/4jj9qHHGcfqxc9yP2j1RXFFRwcqVK+uLxI0ZM4Zp06apSJyIdAm6aqgV4+f+HQQ++K8LPNrL5/NRXl5OeXl5SGMTEQkFjQjC5Ny5c6xevbq+SNz999/P+PHjvQ5LROQaSgRhcv78efbu3cvx48cBFYkTka5LiSCESkpK2LFjBwBDhgzhscceY8iQIR5HJSLSMiWCEHr33XfJy8tTkTgRiSiaLA5SUVER3bt3ry8SB6hInIhEFI0IglBeXs7y5cuvKhKXkpLicVQiIu2jEUEHnDlzht69e+P3+7n33ntVJE5EIppGBO20e/dufvnLX3LkyBEAbrjhBs0FiEhEUyJoo8rK2iqkI0aMYMqUKQwcONDjiEREQkOJoA3eeustXnzxRWpqavD5fNx1110qEiciUUNzBM2oKwhnZgwePJjExEQViRORqKQRQRMqKir4j//4Dz799FOgtkjc1KlTVSRORKJSUInAzHqb2QYzOxB47tVMu+fN7KSZ7exI/87m8/morKysnxcQEYlmwY4IlgD5zrkRQH7gfVNeAGYF0T/szp49y6pVq+qLxP3t3/4t2dnZXoUjItJpgk0E84DlgdfLgflNNXLOvQuc6Wj/znDhwgX279+vInEiEnOCTQQDnHPFAIHn/p3cPygnT55k+/btgIrEiUjsavWqITPLo+n7sTwR+nBajOMh4CEgZB/W7733HkeOHGHMmDHEx8eTmJgYku2KiESSVhOBc25Gc+vM7ISZDXTOFZvZQOBkO/ff5v7OuWXAMoDs7OwOX8d57NgxunfvTlpaGrNmzcI5R3y8rqIVkdgV7KmhtcDiwOvFwJpO7t8uZWVlLF++nLfffhuA5ORkFYkTkZgXbCJ4EsgxswNATuA9ZjbIzN6sa2RmLwMfAjeaWaGZPdhS/3BJSkrivvvuIzc3N5y7ERGJKBaJ35bNzs52BQUFXochIhJRzGyrc+6a6+L1zWIRkRinRCAiEuOUCEREYpwSgYhIjFMiEBGJcUoEIiIxTolARCTGKRGIiMS4iPxCmZmVAEdCuMm+wKkQbq8r0jFGBx1jdPDqGIc65/o1XhiRiSDUzKygqW/bRRMdY3TQMUaHrnaMOjUkIhLjlAhERGKcEkGtZV4H0Al0jNFBxxgdutQxao5ARCTGaUQgIhLjlAhERGJczCQCM+ttZhvM7EDguVcz7Z43s5NmtrMj/b3UjmOcZWb7zOygmS1psHysmX1kZp+YWYGZTei86Nsm2GMMrHsksG6Xmf2kcyJvu1AcY2D935uZM7O+4Y+6fULwf/UpM9trZjvMbJWZ9ey04FvRhp+LmdkvAut3mFlWW/uGjXMuJh7AT4AlgddLgB83024ykAXs7Ej/rn6MQBzwGTAcSAC2A6MD69YDswOv5wBve31MYTjGqUAekBh439/rYwr1MQbWDwbWUfvFy75eH1MYfo65QHzg9Y+7yu9jaz+XQJs5wJ8BAyYCf2lr33A9YmZEAMwDlgdeLwfmN9XIOfcucKaj/T3WlhgnAAedc4ecc5XAikA/AAekBV73AIrCF2qHBXuM3wGedM5VADjnToY33A4J9hgBngb+gdqfaVcU1DE659Y756oD7T4C0sMbbpu19nMh8P5FV+sjoKeZDWxj37CIpUQwwDlXDBB47t/J/TtDW2K8Hjja4H1hYBnAY8BTZnYU+Cnwg/CF2mHBHuNIYJKZ/cXM3jGz8WGNtmOCOkYzmwscc85tD3egQQj259jQA9T+hd0VtCXm5tq09XhDLr4zdtJZzCwPuK6JVU90dizhEoJjtCaW1f3V+B3g+86518zsG8BvgRntjzI4YT7GeKAXtUPy8cBKMxvuAmPzzhKuYzSz5MA2cjsaW6iE+edYt48ngGrgpfZFFzatxtxCm7b0DYuoSgTOuWY/tMzshJkNdM4VB4Zh7T0lEGz/kAjBMRZSe/64TjpfnAJaDDwaeP0K8JsQhNxuYT7GQuD1wAf/f5lZDbUFwEpCE33bhPEYM4EMYLuZ1S3fZmYTnHPHQ3YAbRDmnyNmthi4G5je2Ym8BS3G3EqbhDb0DYtYOjW0ltoPOgLPazq5f2doS4xbgBFmlmFmCcDCQD+o/U93V+D1NOBAGGPtqGCPcTW1x4aZjaT2l6+rVbrs8DE65z51zvV3zg1zzg2j9kMnq7OTQBsE9XM0s1nAPwJznXOXOyHetmrp/16dtcD9gauHJgKlgdNjbekbHl7PsnfWA+gD5FP74ZYP9A4sHwS82aDdy0AxUEXtL9GDLfXvSo92HOMcYD+1Vyg80WD5l4Gt1F6t8BdgnNfHFIZjTAD+AOwEtgHTvD6mUB9jo20dpmteNRTsz/EgtefTPwk8fu31MbUUM/Bt4NuB1wY8E1j/KZDdnp9pOB4qMSEiEuNi6dSQiIg0QYlARCTGKRGIiMQ4JQIRkRinRCAiEuOUCEREYpwSgYhIjPv/ukVxWlJVUF0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(data['beta'], res['beta_est'], label = 'GradVI')\n",
    "ax1.scatter(data['beta'], np.squeeze(res_cavi['beta_est']), label = 'CAVI')\n",
    "mpl_utils.plot_diag(ax1)\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6899d6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c2ef51b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X', 'y', 'Xtest', 'ytest', 'n', 'p', 's', 'beta', 'se', 'DSC_DEBUG'])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b961570e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006417003110395275"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(data['ytest'] - np.dot(data['Xtest'], res['beta_est']) - res['intercept']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1959c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fit_gradvi\n",
    "from gradvi.inference import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e7e18ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005789782269593312"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cavi['model']['fit']['sigma2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d90b9042",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_dj': array([500., 500., 500., ..., 500., 500., 500.]),\n",
       " '_init_params': (array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  array([-2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "         -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "         -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "         -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207]),\n",
       "  0.0014724179775473531),\n",
       " '_invert_method': None,\n",
       " '_invert_options': {},\n",
       " '_is_debug': False,\n",
       " '_is_elbo_calc': False,\n",
       " '_is_intercept': True,\n",
       " '_method': 'l-bfgs-b',\n",
       " '_nclbk': 362,\n",
       " '_objtype': 'reparametrize',\n",
       " '_opts': {'maxiter': 2000,\n",
       "  'disp': False,\n",
       "  'ftol': 1e-09,\n",
       "  'gtol': 1e-09,\n",
       "  'maxfun': 20000},\n",
       " 'coef': array([-5.47594726e-09, -7.22650488e-09,  2.03669351e-10, ...,\n",
       "         8.80410184e-09,  6.38169391e-10, -4.35792412e-09]),\n",
       " 'elbo_path': array([ 1.50121696e+04,  1.17179857e+04,  1.10362981e+04,  1.10338192e+04,\n",
       "         1.09968936e+04,  1.09892885e+04,  1.09725328e+04,  1.08869517e+04,\n",
       "         1.08306991e+04,  1.08223418e+04,  1.08198562e+04,  1.08113822e+04,\n",
       "         1.08084336e+04,  1.08082683e+04,  1.08078789e+04,  1.08065638e+04,\n",
       "         1.08040051e+04,  1.07997518e+04,  1.07823937e+04,  1.07503038e+04,\n",
       "         1.07202492e+04,  1.06659765e+04,  1.06632775e+04,  1.05588459e+04,\n",
       "         1.05072465e+04,  1.04083990e+04,  1.02749142e+04,  9.79835487e+03,\n",
       "         9.34422302e+03,  9.17219250e+03,  8.90258958e+03,  8.68088872e+03,\n",
       "         8.35126914e+03,  7.94431473e+03,  7.39363522e+03,  5.74703504e+03,\n",
       "         4.57491600e+03,  3.73681355e+03,  2.98812168e+03,  2.62117234e+03,\n",
       "         1.77368422e+03,  1.22481498e+03,  9.63751795e+02,  6.93949062e+02,\n",
       "         5.98688999e+02,  5.54275987e+02,  5.09444975e+02,  4.79497561e+02,\n",
       "         4.72980070e+02,  4.48608415e+02,  4.27164482e+02,  4.13896797e+02,\n",
       "         3.97007092e+02,  3.64480907e+02,  3.40187868e+02,  3.08317634e+02,\n",
       "         2.65511950e+02,  2.51893591e+02,  2.35881989e+02,  2.15685589e+02,\n",
       "         1.96489348e+02,  1.85535843e+02,  1.72259367e+02,  1.64157424e+02,\n",
       "         1.43273025e+02,  1.24500171e+02,  1.16414116e+02,  1.01962918e+02,\n",
       "         9.55669208e+01,  8.64963837e+01,  8.21424786e+01,  6.68929701e+01,\n",
       "         5.69525752e+01,  4.23185358e+01,  3.95436251e+01,  2.70493945e+01,\n",
       "         1.96153414e+01,  6.99554730e+00,  3.09330355e+00, -5.30132125e+00,\n",
       "        -1.10013720e+01, -2.95338283e+01, -3.54066031e+01, -4.61536655e+01,\n",
       "        -5.53414240e+01, -6.54729242e+01, -7.18443475e+01, -8.34766897e+01,\n",
       "        -9.60893212e+01, -1.01663427e+02, -1.04711906e+02, -1.07549370e+02,\n",
       "        -1.10020080e+02, -1.16082363e+02, -1.26399290e+02, -1.34442929e+02,\n",
       "        -1.43976460e+02, -1.51374990e+02, -1.53557839e+02, -1.56460921e+02,\n",
       "        -1.58847847e+02, -1.60158676e+02, -1.66360257e+02, -1.71549749e+02,\n",
       "        -1.76667539e+02, -1.80623010e+02, -1.87638273e+02, -1.97912263e+02,\n",
       "        -1.98294863e+02, -2.05232984e+02, -2.17046669e+02, -2.18603429e+02,\n",
       "        -2.24343297e+02, -2.26193430e+02, -2.31097479e+02, -2.39881647e+02,\n",
       "        -2.46516923e+02, -2.52772499e+02, -2.56304978e+02, -2.57488763e+02,\n",
       "        -2.64982997e+02, -2.66317786e+02, -2.74365934e+02, -2.78331651e+02,\n",
       "        -2.80729019e+02, -2.83060329e+02, -2.83823663e+02, -2.88487852e+02,\n",
       "        -2.94272848e+02, -3.00085811e+02, -3.06694152e+02, -3.17284920e+02,\n",
       "        -3.24866932e+02, -3.27900326e+02, -3.29295786e+02, -3.30558984e+02,\n",
       "        -3.31356425e+02, -3.34162120e+02, -3.38225280e+02, -3.45101380e+02,\n",
       "        -3.49712929e+02, -3.52851669e+02, -3.56640802e+02, -3.57635845e+02,\n",
       "        -3.59222803e+02, -3.61894379e+02, -3.64293788e+02, -3.66384567e+02,\n",
       "        -3.70734017e+02, -3.73643691e+02, -3.83712451e+02, -3.88982985e+02,\n",
       "        -3.90839330e+02, -3.92527241e+02, -3.95056312e+02, -3.96790129e+02,\n",
       "        -4.00864303e+02, -4.04691095e+02, -4.06555890e+02, -4.07030620e+02,\n",
       "        -4.10305212e+02, -4.16847307e+02, -4.18327736e+02, -4.19659278e+02,\n",
       "        -4.20968934e+02, -4.21722291e+02, -4.23079568e+02, -4.24240027e+02,\n",
       "        -4.25352898e+02, -4.26875766e+02, -4.29274515e+02, -4.29661512e+02,\n",
       "        -4.32179972e+02, -4.32850356e+02, -4.33992443e+02, -4.34908612e+02,\n",
       "        -4.39604535e+02, -4.40923113e+02, -4.42242837e+02, -4.47879536e+02,\n",
       "        -4.52907817e+02, -4.56900628e+02, -4.57925252e+02, -4.62112536e+02,\n",
       "        -4.63022475e+02, -4.63231839e+02, -4.64258403e+02, -4.64993069e+02,\n",
       "        -4.67138186e+02, -4.71844020e+02, -4.73419737e+02, -4.74347974e+02,\n",
       "        -4.74599556e+02, -4.75518624e+02, -4.76019574e+02, -4.77726184e+02,\n",
       "        -4.79026400e+02, -4.81217734e+02, -4.82896564e+02, -4.85250495e+02,\n",
       "        -4.86638140e+02, -4.87279430e+02, -4.87725227e+02, -4.88630183e+02,\n",
       "        -4.88803520e+02, -4.90186772e+02, -4.91548439e+02, -4.93484409e+02,\n",
       "        -4.93940609e+02, -4.97572538e+02, -5.00171106e+02, -5.02223481e+02,\n",
       "        -5.03496886e+02, -5.05123351e+02, -5.05379203e+02, -5.05908823e+02,\n",
       "        -5.06772566e+02, -5.07132716e+02, -5.07732733e+02, -5.08686775e+02,\n",
       "        -5.09125898e+02, -5.10518731e+02, -5.11542550e+02, -5.12194047e+02,\n",
       "        -5.12456229e+02, -5.13145171e+02, -5.14622994e+02, -5.14860496e+02,\n",
       "        -5.15067256e+02, -5.15371671e+02, -5.15473420e+02, -5.15800540e+02,\n",
       "        -5.15917931e+02, -5.16324573e+02, -5.16939147e+02, -5.17190135e+02,\n",
       "        -5.17280733e+02, -5.17362198e+02, -5.17417207e+02, -5.17430706e+02,\n",
       "        -5.17535399e+02, -5.17573775e+02, -5.17642798e+02, -5.17775504e+02,\n",
       "        -5.17875186e+02, -5.18036154e+02, -5.18104093e+02, -5.18181493e+02,\n",
       "        -5.18253101e+02, -5.18335782e+02, -5.18389677e+02, -5.18437721e+02,\n",
       "        -5.18649466e+02, -5.18665088e+02, -5.18851542e+02, -5.19063240e+02,\n",
       "        -5.19139335e+02, -5.19145391e+02, -5.19152036e+02, -5.19160436e+02,\n",
       "        -5.19165740e+02, -5.19170541e+02, -5.19172559e+02, -5.19174291e+02,\n",
       "        -5.19176112e+02, -5.19177125e+02, -5.19177731e+02, -5.19178622e+02,\n",
       "        -5.19189466e+02, -5.19220610e+02, -5.19263883e+02, -5.19272798e+02,\n",
       "        -5.19283874e+02, -5.19292592e+02, -5.19298060e+02, -5.19302301e+02,\n",
       "        -5.19302956e+02, -5.19303603e+02, -5.19303802e+02, -5.19304850e+02,\n",
       "        -5.19307349e+02, -5.19311583e+02, -5.19320798e+02, -5.19329591e+02,\n",
       "        -5.19332968e+02, -5.19335040e+02, -5.19335276e+02, -5.19336191e+02,\n",
       "        -5.19337620e+02, -5.19337826e+02, -5.19337969e+02, -5.19338334e+02,\n",
       "        -5.19339076e+02, -5.19340905e+02, -5.19346377e+02, -5.19350020e+02,\n",
       "        -5.19350753e+02, -5.19352581e+02, -5.19354670e+02, -5.19355921e+02,\n",
       "        -5.19357168e+02, -5.19357723e+02, -5.19358548e+02, -5.19359071e+02,\n",
       "        -5.19359361e+02, -5.19359415e+02, -5.19359514e+02, -5.19359632e+02,\n",
       "        -5.19359951e+02, -5.19360786e+02, -5.19361871e+02, -5.19362487e+02,\n",
       "        -5.19362619e+02, -5.19363150e+02, -5.19363689e+02, -5.19365034e+02,\n",
       "        -5.19368447e+02, -5.19369068e+02, -5.19369245e+02, -5.19372455e+02,\n",
       "        -5.19373855e+02, -5.19375059e+02, -5.19376624e+02, -5.19376937e+02,\n",
       "        -5.19377079e+02, -5.19377132e+02, -5.19377309e+02, -5.19377583e+02,\n",
       "        -5.19377883e+02, -5.19377995e+02, -5.19378356e+02, -5.19378550e+02,\n",
       "        -5.19379060e+02, -5.19379254e+02, -5.19380020e+02, -5.19383572e+02,\n",
       "        -5.19386226e+02, -5.19393912e+02, -5.19396594e+02, -5.19403951e+02,\n",
       "        -5.19405975e+02, -5.19415250e+02, -5.19419580e+02, -5.19441830e+02,\n",
       "        -5.19444753e+02, -5.19446535e+02, -5.19447171e+02, -5.19448004e+02,\n",
       "        -5.19448747e+02, -5.19451204e+02, -5.19451541e+02, -5.19452717e+02,\n",
       "        -5.19452766e+02, -5.19453016e+02, -5.19453146e+02, -5.19453221e+02,\n",
       "        -5.19453669e+02, -5.19454349e+02, -5.19454949e+02, -5.19455239e+02,\n",
       "        -5.19455297e+02, -5.19455326e+02]),\n",
       " 'fitobj':       fun: -31592.49581824498\n",
       "  hess_inv: <10021x10021 LbfgsInvHessProduct with dtype=float64>\n",
       "       jac: array([-9.70302075e-04, -1.12593395e-03, -1.00165772e-04, ...,\n",
       "        -1.39282222e-01, -1.41984149e-01,  8.91760951e+00])\n",
       "   message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "      nfev: 590\n",
       "       nit: 362\n",
       "      njev: 590\n",
       "    status: 0\n",
       "   success: True\n",
       "         x: array([-7.65812771e-03, -8.17571977e-03,  1.08438924e-03, ...,\n",
       "        -4.50063972e+00, -4.51439404e+00,  6.79977278e-03]),\n",
       " 'fun': -31592.49581824498,\n",
       " 'grad': array([-9.70302075e-04, -1.12593395e-03, -1.00165772e-04, ...,\n",
       "        -1.39282222e-01, -1.41984149e-01,  8.91760951e+00]),\n",
       " 'intercept': 0.00822464490122526,\n",
       " 'nfev': 590,\n",
       " 'niter': 362,\n",
       " 'njev': 590,\n",
       " 'obj_path': [-16060.870941294226,\n",
       "  -19355.05481810791,\n",
       "  -20036.742382557208,\n",
       "  -20039.2213344973,\n",
       "  -20076.14692236542,\n",
       "  -20083.75198442083,\n",
       "  -20100.507687637746,\n",
       "  -20186.088786394852,\n",
       "  -20242.34137103258,\n",
       "  -20250.698672212733,\n",
       "  -20253.184298558794,\n",
       "  -20261.658335597018,\n",
       "  -20264.60689280639,\n",
       "  -20264.77220031343,\n",
       "  -20265.16159122267,\n",
       "  -20266.4766440509,\n",
       "  -20269.035404392664,\n",
       "  -20273.288715985276,\n",
       "  -20290.646752389144,\n",
       "  -20322.7367343842,\n",
       "  -20352.791272798615,\n",
       "  -20407.064002806623,\n",
       "  -20409.76295278883,\n",
       "  -20514.19464146717,\n",
       "  -20565.79398122161,\n",
       "  -20664.641447180366,\n",
       "  -20798.12625304116,\n",
       "  -21274.68562002364,\n",
       "  -21728.8174764848,\n",
       "  -21900.847990745548,\n",
       "  -22170.450908367187,\n",
       "  -22392.151767158983,\n",
       "  -22721.771354256583,\n",
       "  -23128.72576498641,\n",
       "  -23679.405271541225,\n",
       "  -25326.00545448104,\n",
       "  -26498.124487172972,\n",
       "  -27336.22693826902,\n",
       "  -28084.918811687086,\n",
       "  -28451.868147631092,\n",
       "  -29299.35627180229,\n",
       "  -29848.22551024614,\n",
       "  -30109.28869713516,\n",
       "  -30379.091430327553,\n",
       "  -30474.351493581475,\n",
       "  -30518.76450502892,\n",
       "  -30563.595517520225,\n",
       "  -30593.54293115934,\n",
       "  -30600.060422234183,\n",
       "  -30624.43207665533,\n",
       "  -30645.87601014139,\n",
       "  -30659.14369489262,\n",
       "  -30676.033400492488,\n",
       "  -30708.559585259758,\n",
       "  -30732.85262427148,\n",
       "  -30764.722857750527,\n",
       "  -30807.528542567317,\n",
       "  -30821.146901104137,\n",
       "  -30837.158502637914,\n",
       "  -30857.354903502575,\n",
       "  -30876.551143763485,\n",
       "  -30887.504648897295,\n",
       "  -30900.781125114518,\n",
       "  -30908.883067645187,\n",
       "  -30929.76746752365,\n",
       "  -30948.54032100796,\n",
       "  -30956.626376366356,\n",
       "  -30971.077574375933,\n",
       "  -30977.473571333678,\n",
       "  -30986.54410843244,\n",
       "  -30990.898013476155,\n",
       "  -31006.147522021438,\n",
       "  -31016.087916865366,\n",
       "  -31030.72195630608,\n",
       "  -31033.496867033544,\n",
       "  -31045.991097636117,\n",
       "  -31053.42515070928,\n",
       "  -31066.044944813577,\n",
       "  -31069.947188562855,\n",
       "  -31078.341813359904,\n",
       "  -31084.041864106795,\n",
       "  -31102.574320369,\n",
       "  -31108.447095212665,\n",
       "  -31119.19415756152,\n",
       "  -31128.38191606842,\n",
       "  -31138.513416292248,\n",
       "  -31144.88483956705,\n",
       "  -31156.51718176421,\n",
       "  -31169.12981328015,\n",
       "  -31174.70391956241,\n",
       "  -31177.75239764937,\n",
       "  -31180.589862147513,\n",
       "  -31183.06057229894,\n",
       "  -31189.122855275516,\n",
       "  -31199.43978239261,\n",
       "  -31207.483421339515,\n",
       "  -31217.01695220588,\n",
       "  -31224.415482002332,\n",
       "  -31226.598330888963,\n",
       "  -31229.501413524136,\n",
       "  -31231.888339479086,\n",
       "  -31233.19916766751,\n",
       "  -31239.40074908879,\n",
       "  -31244.59024126313,\n",
       "  -31249.70803112638,\n",
       "  -31253.663501711635,\n",
       "  -31260.67876559472,\n",
       "  -31270.952755044593,\n",
       "  -31271.33535526563,\n",
       "  -31278.273476602622,\n",
       "  -31290.087161402367,\n",
       "  -31291.643920870847,\n",
       "  -31297.383789252697,\n",
       "  -31299.233922414627,\n",
       "  -31304.137971601023,\n",
       "  -31312.92213896312,\n",
       "  -31319.557414663817,\n",
       "  -31325.812991033374,\n",
       "  -31329.34546983967,\n",
       "  -31330.52925493743,\n",
       "  -31338.023489409337,\n",
       "  -31339.35827780117,\n",
       "  -31347.406426427257,\n",
       "  -31351.37214294599,\n",
       "  -31353.76951135205,\n",
       "  -31356.100821272605,\n",
       "  -31356.864155331008,\n",
       "  -31361.52834444915,\n",
       "  -31367.313340219604,\n",
       "  -31373.12630357826,\n",
       "  -31379.734644553027,\n",
       "  -31390.325412226182,\n",
       "  -31397.907423736648,\n",
       "  -31400.94081785351,\n",
       "  -31402.33627762087,\n",
       "  -31403.59947567862,\n",
       "  -31404.39691739506,\n",
       "  -31407.202612214467,\n",
       "  -31411.2657723923,\n",
       "  -31418.1418718375,\n",
       "  -31422.753420716126,\n",
       "  -31425.892160638898,\n",
       "  -31429.68129419189,\n",
       "  -31430.676337174882,\n",
       "  -31432.263295168195,\n",
       "  -31434.934870621037,\n",
       "  -31437.33427987024,\n",
       "  -31439.4250590199,\n",
       "  -31443.77450942574,\n",
       "  -31446.684182999124,\n",
       "  -31456.752943128195,\n",
       "  -31462.023477587416,\n",
       "  -31463.879821919127,\n",
       "  -31465.567733300413,\n",
       "  -31468.096804026467,\n",
       "  -31469.830620800094,\n",
       "  -31473.90479516372,\n",
       "  -31477.731587244205,\n",
       "  -31479.596382037562,\n",
       "  -31480.071111890535,\n",
       "  -31483.345703614876,\n",
       "  -31489.887799239208,\n",
       "  -31491.3682276985,\n",
       "  -31492.699769759223,\n",
       "  -31494.009426030534,\n",
       "  -31494.76278266922,\n",
       "  -31496.120060366968,\n",
       "  -31497.28051866594,\n",
       "  -31498.39339048718,\n",
       "  -31499.91625851814,\n",
       "  -31502.315007363348,\n",
       "  -31502.70200363311,\n",
       "  -31505.220464124915,\n",
       "  -31505.890847763076,\n",
       "  -31507.032935064017,\n",
       "  -31507.949104051913,\n",
       "  -31512.64502759028,\n",
       "  -31513.96360475938,\n",
       "  -31515.283329394526,\n",
       "  -31520.920027671113,\n",
       "  -31525.948309157342,\n",
       "  -31529.94111993693,\n",
       "  -31530.965744546673,\n",
       "  -31535.153028223205,\n",
       "  -31536.062966690428,\n",
       "  -31536.272330665022,\n",
       "  -31537.298895203552,\n",
       "  -31538.03356158025,\n",
       "  -31540.178677727577,\n",
       "  -31544.88451188983,\n",
       "  -31546.46022941032,\n",
       "  -31547.388466412696,\n",
       "  -31547.64004818196,\n",
       "  -31548.559116088443,\n",
       "  -31549.06006591861,\n",
       "  -31550.76667567095,\n",
       "  -31552.06689210086,\n",
       "  -31554.258225750404,\n",
       "  -31555.93705575505,\n",
       "  -31558.290986983688,\n",
       "  -31559.67863172471,\n",
       "  -31560.319922069437,\n",
       "  -31560.765719498475,\n",
       "  -31561.670675161968,\n",
       "  -31561.844012324906,\n",
       "  -31563.227263894252,\n",
       "  -31564.588930974758,\n",
       "  -31566.524901275654,\n",
       "  -31566.981100728597,\n",
       "  -31570.613030232904,\n",
       "  -31573.21159821908,\n",
       "  -31575.263973153586,\n",
       "  -31576.53737849639,\n",
       "  -31578.163843013273,\n",
       "  -31578.419694711087,\n",
       "  -31578.949315206082,\n",
       "  -31579.813058285392,\n",
       "  -31580.173208061475,\n",
       "  -31580.773225241734,\n",
       "  -31581.72726731344,\n",
       "  -31582.166389983897,\n",
       "  -31583.55922308768,\n",
       "  -31584.583042073435,\n",
       "  -31585.234538646408,\n",
       "  -31585.49672077858,\n",
       "  -31586.18566321891,\n",
       "  -31587.663485704143,\n",
       "  -31587.900987698733,\n",
       "  -31588.10774831772,\n",
       "  -31588.412163597786,\n",
       "  -31588.513911752583,\n",
       "  -31588.84103164872,\n",
       "  -31588.958423085573,\n",
       "  -31589.36506508856,\n",
       "  -31589.979638877914,\n",
       "  -31590.23062681892,\n",
       "  -31590.321225495132,\n",
       "  -31590.40268973678,\n",
       "  -31590.45769912104,\n",
       "  -31590.471198526502,\n",
       "  -31590.57589109642,\n",
       "  -31590.614266884528,\n",
       "  -31590.683290409776,\n",
       "  -31590.815996046716,\n",
       "  -31590.91567821204,\n",
       "  -31591.076646275607,\n",
       "  -31591.14458542908,\n",
       "  -31591.22198477172,\n",
       "  -31591.293593172213,\n",
       "  -31591.376274118047,\n",
       "  -31591.430169042327,\n",
       "  -31591.478213589482,\n",
       "  -31591.689957844355,\n",
       "  -31591.705580349117,\n",
       "  -31591.892034521654,\n",
       "  -31592.103732391082,\n",
       "  -31592.179827335334,\n",
       "  -31592.18588261742,\n",
       "  -31592.192528500975,\n",
       "  -31592.200928217182,\n",
       "  -31592.20623243183,\n",
       "  -31592.211032953775,\n",
       "  -31592.21305088923,\n",
       "  -31592.21478346821,\n",
       "  -31592.21660361402,\n",
       "  -31592.217616981055,\n",
       "  -31592.218223215496,\n",
       "  -31592.219113993444,\n",
       "  -31592.229958137243,\n",
       "  -31592.26110203013,\n",
       "  -31592.304375239553,\n",
       "  -31592.313290418824,\n",
       "  -31592.32436602087,\n",
       "  -31592.333084316087,\n",
       "  -31592.338552104295,\n",
       "  -31592.342792735537,\n",
       "  -31592.343447982832,\n",
       "  -31592.3440953878,\n",
       "  -31592.344294499188,\n",
       "  -31592.345342442626,\n",
       "  -31592.347840772833,\n",
       "  -31592.352075091294,\n",
       "  -31592.36128976035,\n",
       "  -31592.370083332316,\n",
       "  -31592.373460115206,\n",
       "  -31592.375531855625,\n",
       "  -31592.375767804733,\n",
       "  -31592.37668342874,\n",
       "  -31592.378112599254,\n",
       "  -31592.3783184978,\n",
       "  -31592.378460717846,\n",
       "  -31592.37882629137,\n",
       "  -31592.37956818982,\n",
       "  -31592.381397267847,\n",
       "  -31592.386869314825,\n",
       "  -31592.390511732243,\n",
       "  -31592.391245452345,\n",
       "  -31592.393072959214,\n",
       "  -31592.395162284152,\n",
       "  -31592.39641296768,\n",
       "  -31592.397659992654,\n",
       "  -31592.398215161917,\n",
       "  -31592.39904036282,\n",
       "  -31592.399563169332,\n",
       "  -31592.399853444844,\n",
       "  -31592.39990745054,\n",
       "  -31592.400006496242,\n",
       "  -31592.400124261643,\n",
       "  -31592.40044319381,\n",
       "  -31592.40127812868,\n",
       "  -31592.402363315872,\n",
       "  -31592.402978651306,\n",
       "  -31592.403110718045,\n",
       "  -31592.403641675875,\n",
       "  -31592.404181572623,\n",
       "  -31592.40552578804,\n",
       "  -31592.40893889885,\n",
       "  -31592.409560504297,\n",
       "  -31592.40973733978,\n",
       "  -31592.412946819706,\n",
       "  -31592.414347025144,\n",
       "  -31592.41555139638,\n",
       "  -31592.41711653964,\n",
       "  -31592.4174287435,\n",
       "  -31592.417571201884,\n",
       "  -31592.41762451487,\n",
       "  -31592.417801352436,\n",
       "  -31592.418075361828,\n",
       "  -31592.41837510779,\n",
       "  -31592.418487487044,\n",
       "  -31592.41884827234,\n",
       "  -31592.419042584937,\n",
       "  -31592.41955163284,\n",
       "  -31592.419746133775,\n",
       "  -31592.420512092696,\n",
       "  -31592.42406396038,\n",
       "  -31592.426718122242,\n",
       "  -31592.43440431562,\n",
       "  -31592.437086489263,\n",
       "  -31592.444442894743,\n",
       "  -31592.4464669842,\n",
       "  -31592.455742460825,\n",
       "  -31592.46007251345,\n",
       "  -31592.4823219538,\n",
       "  -31592.485245130283,\n",
       "  -31592.487026611387,\n",
       "  -31592.48766287052,\n",
       "  -31592.488496430007,\n",
       "  -31592.489238929807,\n",
       "  -31592.49169604787,\n",
       "  -31592.49203277567,\n",
       "  -31592.4932093949,\n",
       "  -31592.49325764623,\n",
       "  -31592.49350850122,\n",
       "  -31592.493638268777,\n",
       "  -31592.493713115546,\n",
       "  -31592.49416127682,\n",
       "  -31592.494841124797,\n",
       "  -31592.495440804516,\n",
       "  -31592.495730925577,\n",
       "  -31592.495789416676,\n",
       "  -31592.49581824498],\n",
       " 'prior': {'smbase': 2.718281828459045,\n",
       "  'sk': array([0.        , 0.03526492, 0.07177346, 0.10956947, 0.14869835,\n",
       "         0.18920712, 0.23114441, 0.27456063, 0.31950791, 0.36604026,\n",
       "         0.41421356, 0.4640857 , 0.51571657, 0.5691682 , 0.62450479,\n",
       "         0.68179283, 0.74110113, 0.80250093, 0.86606598, 0.93187266]),\n",
       "  'w': array([9.99999306e-01, 3.54315796e-07, 9.43456734e-08, 4.16160155e-08,\n",
       "         2.62535905e-08, 1.98261151e-08, 1.64713080e-08, 1.44588874e-08,\n",
       "         1.31367735e-08, 1.22137780e-08, 1.15406810e-08, 1.10320434e-08,\n",
       "         1.06352909e-08, 1.03167452e-08, 1.00542837e-08, 9.83316637e-09,\n",
       "         9.64383705e-09, 9.48061936e-09, 9.33956072e-09, 9.21198087e-09]),\n",
       "  'wmod': array([13.9883662 , -0.86471035, -2.18793353, -3.00641386, -3.46709618,\n",
       "         -3.74789893, -3.93327899, -4.06358968, -4.15948351, -4.23233428,\n",
       "         -4.28902068, -4.33409487, -4.37072114, -4.40113063, -4.42690016,\n",
       "         -4.44913795, -4.46857988, -4.4856493 , -4.50063972, -4.51439404]),\n",
       "  'w_init': array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "         0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]),\n",
       "  'wmod_init': array([-2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "         -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "         -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "         -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207]),\n",
       "  'is_scaled': True},\n",
       " 'residual_var': 0.006799772775137751,\n",
       " 'success': True,\n",
       " 'theta': array([-0.00765813, -0.00817572,  0.00108439, ...,  0.00852778,\n",
       "         0.00290918, -0.00721077])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fc067fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = fit_gradvi.get_ash_scaled(sparsity = None, ncomp = 20, skbase = 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2277ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gv1 = LinearRegression(debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bbc93349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.03526492, 0.07177346, 0.10956947, 0.14869835,\n",
       "       0.18920712, 0.23114441, 0.27456063, 0.31950791, 0.36604026,\n",
       "       0.41421356, 0.4640857 , 0.51571657, 0.5691682 , 0.62450479,\n",
       "       0.68179283, 0.74110113, 0.80250093, 0.86606598, 0.93187266])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior.sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c9624ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:26:43,903 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:43,904 | gradvi.models.linear_model               | DEBUG   | Residual variance = 1.0\n",
      "2022-07-06 10:26:44,038 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:44,039 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.9996019222038361\n",
      "2022-07-06 10:26:44,198 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:44,199 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.9980096110191808\n",
      "2022-07-06 10:26:44,331 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 1\n",
      "2022-07-06 10:26:44,334 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:44,334 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.536305813040649\n",
      "2022-07-06 10:26:44,468 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 2\n",
      "2022-07-06 10:26:44,470 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:44,470 | gradvi.models.linear_model               | DEBUG   | Residual variance = 1e-08\n",
      "2022-07-06 10:26:44,612 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:44,614 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.35753721489168966\n",
      "2022-07-06 10:26:44,728 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:44,729 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.1787686124458448\n",
      "2022-07-06 10:26:44,870 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:44,871 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0595895508152956\n",
      "2022-07-06 10:26:44,966 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:44,967 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.019863196938447403\n",
      "2022-07-06 10:26:45,061 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 3\n",
      "2022-07-06 10:26:45,062 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:45,063 | gradvi.models.linear_model               | DEBUG   | Residual variance = 1e-08\n",
      "2022-07-06 10:26:45,178 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:45,180 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.013242137954410028\n",
      "2022-07-06 10:26:45,293 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 4\n",
      "2022-07-06 10:26:45,295 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:45,295 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.015804394327733486\n",
      "2022-07-06 10:26:45,392 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 5\n",
      "2022-07-06 10:26:45,394 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:45,394 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014908834357884282\n",
      "2022-07-06 10:26:45,528 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 6\n",
      "2022-07-06 10:26:45,531 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:45,532 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014659831467675933\n",
      "2022-07-06 10:26:45,665 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 7\n",
      "2022-07-06 10:26:45,668 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:45,668 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014694639265442592\n",
      "2022-07-06 10:26:45,802 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 8\n",
      "2022-07-06 10:26:45,806 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:45,807 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014694784677089758\n",
      "2022-07-06 10:26:45,940 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:45,941 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014695366323678422\n",
      "2022-07-06 10:26:46,075 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:46,076 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014697692910033078\n",
      "2022-07-06 10:26:46,209 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:46,210 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014706999255451703\n",
      "2022-07-06 10:26:46,341 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:46,342 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014744224637126203\n",
      "2022-07-06 10:26:46,472 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 9\n",
      "2022-07-06 10:26:46,476 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:46,476 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014795405664970772\n",
      "2022-07-06 10:26:46,606 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 10\n",
      "2022-07-06 10:26:46,610 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:46,611 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014764130293538005\n",
      "2022-07-06 10:26:46,742 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 11\n",
      "2022-07-06 10:26:46,748 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:46,748 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014720440695443354\n",
      "2022-07-06 10:26:46,841 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 12\n",
      "2022-07-06 10:26:46,844 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:46,845 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.01470663244754004\n",
      "2022-07-06 10:26:46,976 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 13\n",
      "2022-07-06 10:26:46,980 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:46,981 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014710086447905217\n",
      "2022-07-06 10:26:47,111 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 14\n",
      "2022-07-06 10:26:47,116 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:26:47,117 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014717808094033898\n",
      "2022-07-06 10:26:47,248 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 15\n",
      "2022-07-06 10:26:47,252 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:47,253 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014721848332279491\n",
      "2022-07-06 10:26:47,383 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 16\n",
      "2022-07-06 10:26:47,387 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:47,388 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014722373912790706\n",
      "2022-07-06 10:26:47,525 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 17\n",
      "2022-07-06 10:26:47,530 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:47,530 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014721630110026113\n",
      "2022-07-06 10:26:47,663 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:47,664 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014718654898967738\n",
      "2022-07-06 10:26:47,796 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:47,797 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.01470675405473424\n",
      "2022-07-06 10:26:47,936 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:47,937 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.01465915067780025\n",
      "2022-07-06 10:26:48,072 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:48,073 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014706654629889649\n",
      "2022-07-06 10:26:48,210 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:48,211 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014665537787791925\n",
      "2022-07-06 10:26:48,334 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:48,335 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014686096208840786\n",
      "2022-07-06 10:26:48,428 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:48,429 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014672052952510452\n",
      "2022-07-06 10:26:48,524 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:48,525 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014671088112987677\n",
      "2022-07-06 10:26:48,659 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 18\n",
      "2022-07-06 10:26:48,662 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:48,663 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.01452599175631726\n",
      "2022-07-06 10:26:48,802 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:48,803 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014671046803516559\n",
      "2022-07-06 10:26:48,934 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 19\n",
      "2022-07-06 10:26:48,938 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:48,939 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0111528934467055\n",
      "2022-07-06 10:26:49,073 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:49,073 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014052754440869808\n",
      "2022-07-06 10:26:49,206 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:49,206 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.014476622589607177\n",
      "2022-07-06 10:26:49,325 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 20\n",
      "2022-07-06 10:26:49,328 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:49,328 | gradvi.models.linear_model               | DEBUG   | Residual variance = 1e-08\n",
      "2022-07-06 10:26:49,457 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:49,458 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00965108839252265\n",
      "2022-07-06 10:26:49,590 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:49,590 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.012718702915396478\n",
      "2022-07-06 10:26:49,721 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:49,722 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0135529523212048\n",
      "2022-07-06 10:26:49,854 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 21\n",
      "2022-07-06 10:26:49,857 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:49,858 | gradvi.models.linear_model               | DEBUG   | Residual variance = 1e-08\n",
      "2022-07-06 10:26:49,990 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:49,991 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.009035308210441677\n",
      "2022-07-06 10:26:50,122 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 22\n",
      "2022-07-06 10:26:50,125 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:50,126 | gradvi.models.linear_model               | DEBUG   | Residual variance = 1e-08\n",
      "2022-07-06 10:26:50,257 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:50,258 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006023545472949579\n",
      "2022-07-06 10:26:50,389 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:50,390 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.008122266678869833\n",
      "2022-07-06 10:26:50,521 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:50,522 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.008999027027208683\n",
      "2022-07-06 10:26:50,652 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:50,653 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.008775183516513954\n",
      "2022-07-06 10:26:50,786 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:26:50,786 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00893759504137544\n",
      "2022-07-06 10:26:50,886 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 23\n",
      "2022-07-06 10:26:50,889 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:50,890 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.004410026278065337\n",
      "2022-07-06 10:26:51,006 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:51,007 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00765462179835638\n",
      "2022-07-06 10:26:51,138 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 24\n",
      "2022-07-06 10:26:51,141 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:51,142 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00741776186902214\n",
      "2022-07-06 10:26:51,273 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 25\n",
      "2022-07-06 10:26:51,277 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:51,278 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0058427231284417565\n",
      "2022-07-06 10:26:51,411 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:51,412 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.007051409294011094\n",
      "2022-07-06 10:26:51,543 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 26\n",
      "2022-07-06 10:26:51,551 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:51,551 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006057492972889849\n",
      "2022-07-06 10:26:51,691 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:51,692 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006947872867378322\n",
      "2022-07-06 10:26:51,830 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 27\n",
      "2022-07-06 10:26:51,834 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:51,835 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.007386348809867437\n",
      "2022-07-06 10:26:51,970 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 28\n",
      "2022-07-06 10:26:51,975 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:51,976 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.007078619703076669\n",
      "2022-07-06 10:26:52,110 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 29\n",
      "2022-07-06 10:26:52,114 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:52,114 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0068750814762456565\n",
      "2022-07-06 10:26:52,253 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 30\n",
      "2022-07-06 10:26:52,257 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:52,257 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006738530301108996\n",
      "2022-07-06 10:26:52,392 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 31\n",
      "2022-07-06 10:26:52,396 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:52,396 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006781892008265288\n",
      "2022-07-06 10:26:52,531 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 32\n",
      "2022-07-06 10:26:52,535 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:52,536 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006786507894326206\n",
      "2022-07-06 10:26:52,673 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 33\n",
      "2022-07-06 10:26:52,677 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:52,677 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006792380057919385\n",
      "2022-07-06 10:26:52,821 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 34\n",
      "2022-07-06 10:26:52,825 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:52,825 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006784035111842788\n",
      "2022-07-06 10:26:52,962 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 35\n",
      "2022-07-06 10:26:52,966 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:52,966 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006446687992795679\n",
      "2022-07-06 10:26:53,092 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:53,093 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006743342078348206\n",
      "2022-07-06 10:26:53,211 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 36\n",
      "2022-07-06 10:26:53,214 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:53,215 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006760818278460734\n",
      "2022-07-06 10:26:53,366 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 37\n",
      "2022-07-06 10:26:53,370 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:53,371 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00677141855499831\n",
      "2022-07-06 10:26:53,490 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 38\n",
      "2022-07-06 10:26:53,495 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:53,495 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006769634096263062\n",
      "2022-07-06 10:26:53,611 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 39\n",
      "2022-07-06 10:26:53,614 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:53,615 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006913953187723884\n",
      "2022-07-06 10:26:53,714 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:53,715 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006807958181573326\n",
      "2022-07-06 10:26:53,838 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 40\n",
      "2022-07-06 10:26:53,842 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:53,842 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006796078066441864\n",
      "2022-07-06 10:26:53,979 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:26:53,984 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:53,984 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0067816055940472155\n",
      "2022-07-06 10:26:54,108 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 42\n",
      "2022-07-06 10:26:54,113 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:54,113 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006759880608452292\n",
      "2022-07-06 10:26:54,245 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:54,246 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00678156331250357\n",
      "2022-07-06 10:26:54,365 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:54,367 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0067742989974736816\n",
      "2022-07-06 10:26:54,506 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:54,507 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006779333491381069\n",
      "2022-07-06 10:26:54,647 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 43\n",
      "2022-07-06 10:26:54,651 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:54,651 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0067579231231944484\n",
      "2022-07-06 10:26:54,775 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:54,776 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006768357793668938\n",
      "2022-07-06 10:26:54,915 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 44\n",
      "2022-07-06 10:26:54,920 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:54,921 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006766558467643172\n",
      "2022-07-06 10:26:55,057 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 45\n",
      "2022-07-06 10:26:55,060 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:55,061 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006747987438597597\n",
      "2022-07-06 10:26:55,197 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:55,198 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006761823847146235\n",
      "2022-07-06 10:26:55,333 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 46\n",
      "2022-07-06 10:26:55,337 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:55,338 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006913962255075881\n",
      "2022-07-06 10:26:55,474 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:55,475 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0067784886372839\n",
      "2022-07-06 10:26:55,573 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 47\n",
      "2022-07-06 10:26:55,577 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:55,578 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006765134438092102\n",
      "2022-07-06 10:26:55,714 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 48\n",
      "2022-07-06 10:26:55,718 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:55,718 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006769422724594462\n",
      "2022-07-06 10:26:55,865 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 49\n",
      "2022-07-06 10:26:55,869 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:55,869 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006789748162892406\n",
      "2022-07-06 10:26:56,009 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 50\n",
      "2022-07-06 10:26:56,013 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:56,014 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00679776744693353\n",
      "2022-07-06 10:26:56,110 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 51\n",
      "2022-07-06 10:26:56,114 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:56,114 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006819307461714011\n",
      "2022-07-06 10:26:56,251 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 52\n",
      "2022-07-06 10:26:56,255 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:56,255 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006836746446444803\n",
      "2022-07-06 10:26:56,390 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 53\n",
      "2022-07-06 10:26:56,395 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:56,395 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006781310125271713\n",
      "2022-07-06 10:26:56,493 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 54\n",
      "2022-07-06 10:26:56,497 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:56,498 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006740500755704315\n",
      "2022-07-06 10:26:56,626 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 55\n",
      "2022-07-06 10:26:56,632 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:56,632 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006745924646108573\n",
      "2022-07-06 10:26:56,770 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 56\n",
      "2022-07-06 10:26:56,774 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:56,775 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006742394889667188\n",
      "2022-07-06 10:26:56,905 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:56,906 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006744023061104371\n",
      "2022-07-06 10:26:57,015 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 57\n",
      "2022-07-06 10:26:57,019 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:57,020 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00705408624578139\n",
      "2022-07-06 10:26:57,157 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:26:57,158 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006785727044909858\n",
      "2022-07-06 10:26:57,293 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 58\n",
      "2022-07-06 10:26:57,297 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:57,298 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006770435625699532\n",
      "2022-07-06 10:26:57,439 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 59\n",
      "2022-07-06 10:26:57,443 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:57,444 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006729423863786853\n",
      "2022-07-06 10:26:57,580 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 60\n",
      "2022-07-06 10:26:57,584 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:57,585 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006731841050097561\n",
      "2022-07-06 10:26:57,722 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 61\n",
      "2022-07-06 10:26:57,725 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:57,726 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006742923554361538\n",
      "2022-07-06 10:26:57,829 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 62\n",
      "2022-07-06 10:26:57,832 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:57,833 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006731872305233063\n",
      "2022-07-06 10:26:57,931 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:57,932 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006737898060099155\n",
      "2022-07-06 10:26:58,042 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 63\n",
      "2022-07-06 10:26:58,046 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:58,046 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006774122493468576\n",
      "2022-07-06 10:26:58,143 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:58,144 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006751394558684067\n",
      "2022-07-06 10:26:58,282 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 64\n",
      "2022-07-06 10:26:58,287 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:58,287 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006729578516403585\n",
      "2022-07-06 10:26:58,399 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:58,400 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006740698853460521\n",
      "2022-07-06 10:26:58,497 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 65\n",
      "2022-07-06 10:26:58,500 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:58,501 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006735532888543004\n",
      "2022-07-06 10:26:58,611 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 66\n",
      "2022-07-06 10:26:58,614 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:58,615 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006732094118065753\n",
      "2022-07-06 10:26:58,753 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 67\n",
      "2022-07-06 10:26:58,757 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:58,758 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006793163213025137\n",
      "2022-07-06 10:26:58,895 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:58,896 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006754964137974888\n",
      "2022-07-06 10:26:59,020 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 68\n",
      "2022-07-06 10:26:59,024 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,024 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0067030283228359765\n",
      "2022-07-06 10:26:59,131 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 69\n",
      "2022-07-06 10:26:59,135 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,136 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006705099623482791\n",
      "2022-07-06 10:26:59,265 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 70\n",
      "2022-07-06 10:26:59,277 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,278 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006557548652458314\n",
      "2022-07-06 10:26:59,410 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,411 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006674619876262871\n",
      "2022-07-06 10:26:59,524 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 71\n",
      "2022-07-06 10:26:59,527 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,528 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006706091731987517\n",
      "2022-07-06 10:26:59,652 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 72\n",
      "2022-07-06 10:26:59,656 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,657 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006718098525374805\n",
      "2022-07-06 10:26:59,767 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 73\n",
      "2022-07-06 10:26:59,771 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,771 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006725926012265581\n",
      "2022-07-06 10:26:59,884 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 74\n",
      "2022-07-06 10:26:59,888 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,888 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006728156140291241\n",
      "2022-07-06 10:26:59,988 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 75\n",
      "2022-07-06 10:26:59,991 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:26:59,991 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006725172832538095\n",
      "2022-07-06 10:27:00,091 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:00,094 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:00,095 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006747611958376835\n",
      "2022-07-06 10:27:00,218 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:00,219 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006732684823255598\n",
      "2022-07-06 10:27:00,355 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 77\n",
      "2022-07-06 10:27:00,359 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:00,359 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006742052824627264\n",
      "2022-07-06 10:27:00,457 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 78\n",
      "2022-07-06 10:27:00,461 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:00,462 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006779658803632942\n",
      "2022-07-06 10:27:00,597 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 79\n",
      "2022-07-06 10:27:00,601 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:00,601 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00661497634236757\n",
      "2022-07-06 10:27:00,706 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:00,706 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006738852079293917\n",
      "2022-07-06 10:27:00,805 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 80\n",
      "2022-07-06 10:27:00,808 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:00,809 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006711995870919775\n",
      "2022-07-06 10:27:00,925 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 81\n",
      "2022-07-06 10:27:00,928 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:00,928 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006712173235254572\n",
      "2022-07-06 10:27:01,027 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 82\n",
      "2022-07-06 10:27:01,031 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:01,031 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006894079882088576\n",
      "2022-07-06 10:27:01,176 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:01,177 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006731333114566435\n",
      "2022-07-06 10:27:01,317 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 83\n",
      "2022-07-06 10:27:01,321 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:01,323 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006737164716053971\n",
      "2022-07-06 10:27:01,458 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 84\n",
      "2022-07-06 10:27:01,462 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:01,462 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006727591614829084\n",
      "2022-07-06 10:27:01,597 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 85\n",
      "2022-07-06 10:27:01,601 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:01,601 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006713892655439327\n",
      "2022-07-06 10:27:01,729 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 86\n",
      "2022-07-06 10:27:01,734 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:01,734 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006702013106385464\n",
      "2022-07-06 10:27:01,860 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 87\n",
      "2022-07-06 10:27:01,864 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:01,864 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006692039098906008\n",
      "2022-07-06 10:27:01,962 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 88\n",
      "2022-07-06 10:27:01,965 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:01,966 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006687470747415736\n",
      "2022-07-06 10:27:02,069 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 89\n",
      "2022-07-06 10:27:02,072 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:02,073 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006683468868871189\n",
      "2022-07-06 10:27:02,178 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 90\n",
      "2022-07-06 10:27:02,183 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:02,183 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.010156546930160557\n",
      "2022-07-06 10:27:02,304 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:02,305 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006690216534080721\n",
      "2022-07-06 10:27:02,439 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 91\n",
      "2022-07-06 10:27:02,443 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:02,444 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066946854509556415\n",
      "2022-07-06 10:27:02,564 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 92\n",
      "2022-07-06 10:27:02,568 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:02,569 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006698516958057196\n",
      "2022-07-06 10:27:02,705 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 93\n",
      "2022-07-06 10:27:02,708 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:02,709 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006654085251433482\n",
      "2022-07-06 10:27:02,805 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:02,806 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006676278199049372\n",
      "2022-07-06 10:27:02,908 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 94\n",
      "2022-07-06 10:27:02,911 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:02,911 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006684765822627311\n",
      "2022-07-06 10:27:03,032 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 95\n",
      "2022-07-06 10:27:03,036 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:03,037 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006696623525681685\n",
      "2022-07-06 10:27:03,157 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 96\n",
      "2022-07-06 10:27:03,161 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:03,162 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0067017460852375876\n",
      "2022-07-06 10:27:03,290 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 97\n",
      "2022-07-06 10:27:03,293 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:03,294 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006684389181939926\n",
      "2022-07-06 10:27:03,402 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 98\n",
      "2022-07-06 10:27:03,405 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:03,405 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006691038419722578\n",
      "2022-07-06 10:27:03,502 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 99\n",
      "2022-07-06 10:27:03,506 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:03,506 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006690934593137125\n",
      "2022-07-06 10:27:03,602 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 100\n",
      "2022-07-06 10:27:03,605 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:03,606 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006701923827032059\n",
      "2022-07-06 10:27:03,741 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 101\n",
      "2022-07-06 10:27:03,744 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:03,745 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006654859919020597\n",
      "2022-07-06 10:27:03,867 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:03,868 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006680117223404343\n",
      "2022-07-06 10:27:04,001 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 102\n",
      "2022-07-06 10:27:04,005 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,006 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006693399497585992\n",
      "2022-07-06 10:27:04,104 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 103\n",
      "2022-07-06 10:27:04,107 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,107 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006698660373020129\n",
      "2022-07-06 10:27:04,216 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 104\n",
      "2022-07-06 10:27:04,219 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,220 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006575031648462197\n",
      "2022-07-06 10:27:04,338 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,339 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00667417161734852\n",
      "2022-07-06 10:27:04,434 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 105\n",
      "2022-07-06 10:27:04,438 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,438 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006690170440596671\n",
      "2022-07-06 10:27:04,551 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 106\n",
      "2022-07-06 10:27:04,555 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,555 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006698551036106101\n",
      "2022-07-06 10:27:04,651 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 107\n",
      "2022-07-06 10:27:04,654 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,655 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006706925909034721\n",
      "2022-07-06 10:27:04,753 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,754 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006702841502268917\n",
      "2022-07-06 10:27:04,850 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 108\n",
      "2022-07-06 10:27:04,853 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,854 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0067025794498186755\n",
      "2022-07-06 10:27:04,954 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:04,955 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006702716018319162\n",
      "2022-07-06 10:27:05,063 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 109\n",
      "2022-07-06 10:27:05,067 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:05,068 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006778191704993121\n",
      "2022-07-06 10:27:05,188 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:05,189 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006708547079173767\n",
      "2022-07-06 10:27:05,299 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 110\n",
      "2022-07-06 10:27:05,302 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:05,303 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006699795353523044\n",
      "2022-07-06 10:27:05,397 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 111\n",
      "2022-07-06 10:27:05,401 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:05,402 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006562110578036048\n",
      "2022-07-06 10:27:05,496 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:05,497 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006670808743654404\n",
      "2022-07-06 10:27:05,592 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 112\n",
      "2022-07-06 10:27:05,596 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:05,597 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006671110101673221\n",
      "2022-07-06 10:27:05,708 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 113\n",
      "2022-07-06 10:27:05,711 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:05,712 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00665189016224951\n",
      "2022-07-06 10:27:05,809 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:05,810 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006661011645978816\n",
      "2022-07-06 10:27:05,905 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 114\n",
      "2022-07-06 10:27:05,909 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:05,909 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066706187908406895\n",
      "2022-07-06 10:27:06,024 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 115\n",
      "2022-07-06 10:27:06,028 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,029 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00668623124528324\n",
      "2022-07-06 10:27:06,164 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 116\n",
      "2022-07-06 10:27:06,168 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,169 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066759589521166686\n",
      "2022-07-06 10:27:06,288 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 117\n",
      "2022-07-06 10:27:06,291 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,292 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006688790553748582\n",
      "2022-07-06 10:27:06,416 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 118\n",
      "2022-07-06 10:27:06,419 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,419 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006684987393889034\n",
      "2022-07-06 10:27:06,513 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 119\n",
      "2022-07-06 10:27:06,516 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,517 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006681144244938587\n",
      "2022-07-06 10:27:06,615 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 120\n",
      "2022-07-06 10:27:06,618 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,619 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006674290861713001\n",
      "2022-07-06 10:27:06,715 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 121\n",
      "2022-07-06 10:27:06,718 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,719 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006670234542630409\n",
      "2022-07-06 10:27:06,826 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 122\n",
      "2022-07-06 10:27:06,830 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,831 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00667757716428406\n",
      "2022-07-06 10:27:06,962 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:06,963 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006672404484352753\n",
      "2022-07-06 10:27:07,058 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 123\n",
      "2022-07-06 10:27:07,062 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,062 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006697415214030494\n",
      "2022-07-06 10:27:07,162 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 124\n",
      "2022-07-06 10:27:07,166 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,167 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006682081750421999\n",
      "2022-07-06 10:27:07,261 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 125\n",
      "2022-07-06 10:27:07,265 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,266 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006672996928641641\n",
      "2022-07-06 10:27:07,363 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 126\n",
      "2022-07-06 10:27:07,366 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,367 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006668821093076137\n",
      "2022-07-06 10:27:07,477 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 127\n",
      "2022-07-06 10:27:07,480 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,480 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00750321161909895\n",
      "2022-07-06 10:27:07,579 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,580 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006676276193859196\n",
      "2022-07-06 10:27:07,677 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 128\n",
      "2022-07-06 10:27:07,680 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,680 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006677362282162764\n",
      "2022-07-06 10:27:07,798 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 129\n",
      "2022-07-06 10:27:07,801 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,802 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006628549197963043\n",
      "2022-07-06 10:27:07,899 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 130\n",
      "2022-07-06 10:27:07,902 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:07,902 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006666602042835581\n",
      "2022-07-06 10:27:07,998 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 131\n",
      "2022-07-06 10:27:08,002 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,002 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006669297512881957\n",
      "2022-07-06 10:27:08,099 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 132\n",
      "2022-07-06 10:27:08,102 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:08,103 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006669509156124179\n",
      "2022-07-06 10:27:08,205 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,205 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006669403058362234\n",
      "2022-07-06 10:27:08,304 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 133\n",
      "2022-07-06 10:27:08,307 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,308 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066782799142127945\n",
      "2022-07-06 10:27:08,403 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,404 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006671878568537593\n",
      "2022-07-06 10:27:08,523 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 134\n",
      "2022-07-06 10:27:08,527 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,527 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066914105736861\n",
      "2022-07-06 10:27:08,636 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 135\n",
      "2022-07-06 10:27:08,639 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,639 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006695932534775943\n",
      "2022-07-06 10:27:08,736 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 136\n",
      "2022-07-06 10:27:08,740 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,740 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006677693286275542\n",
      "2022-07-06 10:27:08,842 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 137\n",
      "2022-07-06 10:27:08,845 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,846 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006662186023243789\n",
      "2022-07-06 10:27:08,943 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 138\n",
      "2022-07-06 10:27:08,946 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:08,947 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006669809399445119\n",
      "2022-07-06 10:27:09,043 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 139\n",
      "2022-07-06 10:27:09,046 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,047 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006665064434753076\n",
      "2022-07-06 10:27:09,158 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 140\n",
      "2022-07-06 10:27:09,161 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,162 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006707855964125885\n",
      "2022-07-06 10:27:09,259 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,260 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006673920625464398\n",
      "2022-07-06 10:27:09,379 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 141\n",
      "2022-07-06 10:27:09,382 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,383 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006667673674379763\n",
      "2022-07-06 10:27:09,480 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 142\n",
      "2022-07-06 10:27:09,483 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,483 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006666590504298772\n",
      "2022-07-06 10:27:09,581 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 143\n",
      "2022-07-06 10:27:09,584 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,584 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066225536259403766\n",
      "2022-07-06 10:27:09,707 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,708 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006648221482146713\n",
      "2022-07-06 10:27:09,847 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 144\n",
      "2022-07-06 10:27:09,851 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,851 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006650441541608753\n",
      "2022-07-06 10:27:09,960 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 145\n",
      "2022-07-06 10:27:09,963 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:09,964 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006634774581657337\n",
      "2022-07-06 10:27:10,062 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 146\n",
      "2022-07-06 10:27:10,065 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:10,065 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006680506582590686\n",
      "2022-07-06 10:27:10,165 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:10,166 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066570060023306635\n",
      "2022-07-06 10:27:10,262 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 147\n",
      "2022-07-06 10:27:10,268 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:10,268 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006666168274555114\n",
      "2022-07-06 10:27:10,374 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 148\n",
      "2022-07-06 10:27:10,378 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:10,378 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066690179803565175\n",
      "2022-07-06 10:27:10,512 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 149\n",
      "2022-07-06 10:27:10,516 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:10,518 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006667096767100312\n",
      "2022-07-06 10:27:10,617 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 150\n",
      "2022-07-06 10:27:10,621 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:10,622 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006702185250163885\n",
      "2022-07-06 10:27:10,728 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:10,729 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006676137247144303\n",
      "2022-07-06 10:27:10,838 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 151\n",
      "2022-07-06 10:27:10,841 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:10,842 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00665076457950881\n",
      "2022-07-06 10:27:10,939 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 152\n",
      "2022-07-06 10:27:10,942 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:10,942 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066545152501878094\n",
      "2022-07-06 10:27:11,039 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 153\n",
      "2022-07-06 10:27:11,043 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,043 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00666589253152625\n",
      "2022-07-06 10:27:11,144 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 154\n",
      "2022-07-06 10:27:11,151 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,151 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006663902185101063\n",
      "2022-07-06 10:27:11,249 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 155\n",
      "2022-07-06 10:27:11,253 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,253 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006687070921309952\n",
      "2022-07-06 10:27:11,356 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,357 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006670175820546312\n",
      "2022-07-06 10:27:11,481 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 156\n",
      "2022-07-06 10:27:11,490 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,491 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006669054835424798\n",
      "2022-07-06 10:27:11,589 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 157\n",
      "2022-07-06 10:27:11,592 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,593 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006655626536587697\n",
      "2022-07-06 10:27:11,690 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 158\n",
      "2022-07-06 10:27:11,693 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,694 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066566153790117094\n",
      "2022-07-06 10:27:11,797 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,798 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006660570748707761\n",
      "2022-07-06 10:27:11,912 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 159\n",
      "2022-07-06 10:27:11,915 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:11,915 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006662879745709785\n",
      "2022-07-06 10:27:12,013 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 160\n",
      "2022-07-06 10:27:12,017 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,017 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066748476776603205\n",
      "2022-07-06 10:27:12,126 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,127 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006667782805846297\n",
      "2022-07-06 10:27:12,236 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 161\n",
      "2022-07-06 10:27:12,239 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,240 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006684974714803089\n",
      "2022-07-06 10:27:12,368 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,369 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006674083746579517\n",
      "2022-07-06 10:27:12,481 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 162\n",
      "2022-07-06 10:27:12,484 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,485 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006685478050627525\n",
      "2022-07-06 10:27:12,583 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 163\n",
      "2022-07-06 10:27:12,586 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,587 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006612391947926032\n",
      "2022-07-06 10:27:12,683 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,684 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006647645909157367\n",
      "2022-07-06 10:27:12,785 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 164\n",
      "2022-07-06 10:27:12,788 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,789 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006647242028599529\n",
      "2022-07-06 10:27:12,892 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 165\n",
      "2022-07-06 10:27:12,895 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,896 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006669541600378753\n",
      "2022-07-06 10:27:12,989 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:12,990 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006655251949023462\n",
      "2022-07-06 10:27:13,085 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 166\n",
      "2022-07-06 10:27:13,088 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:13,089 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006671711728473071\n",
      "2022-07-06 10:27:13,192 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 167\n",
      "2022-07-06 10:27:13,195 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:13,195 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006670376744964325\n",
      "2022-07-06 10:27:13,299 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 168\n",
      "2022-07-06 10:27:13,302 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:13,303 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0065456588800741336\n",
      "2022-07-06 10:27:13,424 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:13,425 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006649206232958601\n",
      "2022-07-06 10:27:13,518 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 169\n",
      "2022-07-06 10:27:13,522 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:13,523 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006647336380378617\n",
      "2022-07-06 10:27:13,619 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 170\n",
      "2022-07-06 10:27:13,622 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:13,623 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006650365545919035\n",
      "2022-07-06 10:27:13,720 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 171\n",
      "2022-07-06 10:27:13,723 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:13,724 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006658339295354073\n",
      "2022-07-06 10:27:13,858 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 172\n",
      "2022-07-06 10:27:13,861 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:13,862 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006660424237492046\n",
      "2022-07-06 10:27:13,974 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 173\n",
      "2022-07-06 10:27:13,978 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:13,978 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006659385749662026\n",
      "2022-07-06 10:27:14,109 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 174\n",
      "2022-07-06 10:27:14,114 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:14,114 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006170403836633527\n",
      "2022-07-06 10:27:14,248 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:14,249 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006586223682948997\n",
      "2022-07-06 10:27:14,388 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:14,389 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006653756013013803\n",
      "2022-07-06 10:27:14,526 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 175\n",
      "2022-07-06 10:27:14,531 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:14,531 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006645054862411079\n",
      "2022-07-06 10:27:14,668 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 176\n",
      "2022-07-06 10:27:14,673 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:14,674 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00664725496555136\n",
      "2022-07-06 10:27:14,769 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 177\n",
      "2022-07-06 10:27:14,772 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:14,773 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006639960962225146\n",
      "2022-07-06 10:27:14,884 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 178\n",
      "2022-07-06 10:27:14,888 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:14,889 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006650079972380748\n",
      "2022-07-06 10:27:15,002 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 179\n",
      "2022-07-06 10:27:15,006 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:15,006 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006651701157395501\n",
      "2022-07-06 10:27:15,124 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 180\n",
      "2022-07-06 10:27:15,127 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:15,128 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00666016744850043\n",
      "2022-07-06 10:27:15,264 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 181\n",
      "2022-07-06 10:27:15,268 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:15,269 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006653551241980697\n",
      "2022-07-06 10:27:15,402 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 182\n",
      "2022-07-06 10:27:15,407 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:15,407 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006650737418584307\n",
      "2022-07-06 10:27:15,539 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 183\n",
      "2022-07-06 10:27:15,543 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:15,544 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006639542077916542\n",
      "2022-07-06 10:27:15,677 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 184\n",
      "2022-07-06 10:27:15,681 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:15,681 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006640208514096669\n",
      "2022-07-06 10:27:15,804 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 185\n",
      "2022-07-06 10:27:15,808 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:15,809 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0068595038480386865\n",
      "2022-07-06 10:27:15,945 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:15,946 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006650646153811177\n",
      "2022-07-06 10:27:16,086 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 186\n",
      "2022-07-06 10:27:16,090 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:16,091 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006653754791973921\n",
      "2022-07-06 10:27:16,232 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 187\n",
      "2022-07-06 10:27:16,236 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:16,236 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006638837006600351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:16,375 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 188\n",
      "2022-07-06 10:27:16,379 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:16,379 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006641239139870183\n",
      "2022-07-06 10:27:16,514 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 189\n",
      "2022-07-06 10:27:16,519 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:16,520 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006666314854272015\n",
      "2022-07-06 10:27:16,655 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:16,656 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006652069030575455\n",
      "2022-07-06 10:27:16,779 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 190\n",
      "2022-07-06 10:27:16,782 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:16,782 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006652237748219353\n",
      "2022-07-06 10:27:16,912 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 191\n",
      "2022-07-06 10:27:16,915 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:16,916 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006643199044275819\n",
      "2022-07-06 10:27:17,051 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:17,052 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006648059935130543\n",
      "2022-07-06 10:27:17,187 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 192\n",
      "2022-07-06 10:27:17,191 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:17,192 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006645983680343387\n",
      "2022-07-06 10:27:17,329 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 193\n",
      "2022-07-06 10:27:17,333 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:17,333 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006628233332462292\n",
      "2022-07-06 10:27:17,470 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:17,471 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006637710935237289\n",
      "2022-07-06 10:27:17,608 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 194\n",
      "2022-07-06 10:27:17,612 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:17,612 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00664263773268787\n",
      "2022-07-06 10:27:17,738 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 195\n",
      "2022-07-06 10:27:17,742 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:17,742 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006646334438554245\n",
      "2022-07-06 10:27:17,875 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 196\n",
      "2022-07-06 10:27:17,879 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:17,880 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006702232663173737\n",
      "2022-07-06 10:27:18,013 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:18,014 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00666339948198361\n",
      "2022-07-06 10:27:18,147 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 197\n",
      "2022-07-06 10:27:18,155 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:18,155 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006656134468447668\n",
      "2022-07-06 10:27:18,281 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 198\n",
      "2022-07-06 10:27:18,284 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:18,285 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006644497793634196\n",
      "2022-07-06 10:27:18,379 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 199\n",
      "2022-07-06 10:27:18,383 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:18,383 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006645159309369282\n",
      "2022-07-06 10:27:18,516 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 200\n",
      "2022-07-06 10:27:18,520 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:18,520 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066394778407500325\n",
      "2022-07-06 10:27:18,652 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 201\n",
      "2022-07-06 10:27:18,656 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:18,657 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006644076759755718\n",
      "2022-07-06 10:27:18,790 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 202\n",
      "2022-07-06 10:27:18,793 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:18,794 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006645832247296118\n",
      "2022-07-06 10:27:18,926 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 203\n",
      "2022-07-06 10:27:18,929 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:18,930 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006645577921760636\n",
      "2022-07-06 10:27:19,049 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 204\n",
      "2022-07-06 10:27:19,053 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:19,054 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066400255077830594\n",
      "2022-07-06 10:27:19,193 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 205\n",
      "2022-07-06 10:27:19,197 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:19,198 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006646407613857544\n",
      "2022-07-06 10:27:19,325 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:19,325 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006642199115464139\n",
      "2022-07-06 10:27:19,432 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 206\n",
      "2022-07-06 10:27:19,436 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:19,437 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006638573545256415\n",
      "2022-07-06 10:27:19,571 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:19,572 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006640484319815694\n",
      "2022-07-06 10:27:19,680 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 207\n",
      "2022-07-06 10:27:19,683 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:19,684 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.007251830710584736\n",
      "2022-07-06 10:27:19,790 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:19,791 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006649644785776537\n",
      "2022-07-06 10:27:19,908 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:19,909 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00664523068500683\n",
      "2022-07-06 10:27:20,044 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 208\n",
      "2022-07-06 10:27:20,050 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,050 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006644291380414101\n",
      "2022-07-06 10:27:20,166 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 209\n",
      "2022-07-06 10:27:20,171 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,172 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006607615385592291\n",
      "2022-07-06 10:27:20,266 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,267 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006639730496490999\n",
      "2022-07-06 10:27:20,399 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 210\n",
      "2022-07-06 10:27:20,403 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,404 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006640420657910573\n",
      "2022-07-06 10:27:20,518 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 211\n",
      "2022-07-06 10:27:20,522 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,522 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006639105171895486\n",
      "2022-07-06 10:27:20,634 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 212\n",
      "2022-07-06 10:27:20,639 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,639 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006671719088725768\n",
      "2022-07-06 10:27:20,758 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,759 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006648902698831462\n",
      "2022-07-06 10:27:20,874 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 213\n",
      "2022-07-06 10:27:20,877 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,877 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006643882393639038\n",
      "2022-07-06 10:27:20,989 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 214\n",
      "2022-07-06 10:27:20,993 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:20,993 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00663795466156969\n",
      "2022-07-06 10:27:21,120 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 215\n",
      "2022-07-06 10:27:21,124 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:21,124 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006636015645495358\n",
      "2022-07-06 10:27:21,238 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 216\n",
      "2022-07-06 10:27:21,242 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:21,243 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006633533084015462\n",
      "2022-07-06 10:27:21,342 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 217\n",
      "2022-07-06 10:27:21,346 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:21,346 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006635412536515339\n",
      "2022-07-06 10:27:21,487 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:21,488 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006634208977994083\n",
      "2022-07-06 10:27:21,624 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 218\n",
      "2022-07-06 10:27:21,628 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:21,628 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006502678645429891\n",
      "2022-07-06 10:27:21,730 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:21,731 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006629984862249516\n",
      "2022-07-06 10:27:21,827 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 219\n",
      "2022-07-06 10:27:21,830 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:21,831 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006633773877788632\n",
      "2022-07-06 10:27:21,970 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 220\n",
      "2022-07-06 10:27:21,975 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:21,976 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00663486178073886\n",
      "2022-07-06 10:27:22,100 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 221\n",
      "2022-07-06 10:27:22,105 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:22,105 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066777611361645865\n",
      "2022-07-06 10:27:22,222 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:22,223 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006639013111944521\n",
      "2022-07-06 10:27:22,335 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 222\n",
      "2022-07-06 10:27:22,339 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:22,340 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006637473750301902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:22,475 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 223\n",
      "2022-07-06 10:27:22,478 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:22,479 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00662746064231184\n",
      "2022-07-06 10:27:22,572 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 224\n",
      "2022-07-06 10:27:22,576 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:22,576 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066307653981578524\n",
      "2022-07-06 10:27:22,706 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 225\n",
      "2022-07-06 10:27:22,710 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:22,710 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006631560090392441\n",
      "2022-07-06 10:27:22,846 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 226\n",
      "2022-07-06 10:27:22,850 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:22,851 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006630147177011817\n",
      "2022-07-06 10:27:22,985 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 227\n",
      "2022-07-06 10:27:22,989 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:22,990 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006632690831881399\n",
      "2022-07-06 10:27:23,099 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 228\n",
      "2022-07-06 10:27:23,104 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:23,104 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006627652123002005\n",
      "2022-07-06 10:27:23,226 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 229\n",
      "2022-07-06 10:27:23,229 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:23,229 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006593712921593023\n",
      "2022-07-06 10:27:23,356 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:23,357 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006621332789693994\n",
      "2022-07-06 10:27:23,461 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 230\n",
      "2022-07-06 10:27:23,464 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:23,465 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006626816327839508\n",
      "2022-07-06 10:27:23,571 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 231\n",
      "2022-07-06 10:27:23,575 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:23,575 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006629165548864409\n",
      "2022-07-06 10:27:23,724 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 232\n",
      "2022-07-06 10:27:23,728 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:23,728 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006630947008708533\n",
      "2022-07-06 10:27:23,846 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 233\n",
      "2022-07-06 10:27:23,851 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:23,851 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006633426310386351\n",
      "2022-07-06 10:27:23,987 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 234\n",
      "2022-07-06 10:27:23,992 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:23,992 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006625796839851579\n",
      "2022-07-06 10:27:24,107 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 235\n",
      "2022-07-06 10:27:24,111 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:24,111 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006650501897269659\n",
      "2022-07-06 10:27:24,245 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:24,247 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006636914037118978\n",
      "2022-07-06 10:27:24,387 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 236\n",
      "2022-07-06 10:27:24,391 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:24,391 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006630825319643781\n",
      "2022-07-06 10:27:24,531 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 237\n",
      "2022-07-06 10:27:24,535 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:24,535 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006625353722586834\n",
      "2022-07-06 10:27:24,641 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 238\n",
      "2022-07-06 10:27:24,644 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:24,644 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006625190971741105\n",
      "2022-07-06 10:27:24,786 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 239\n",
      "2022-07-06 10:27:24,789 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:24,790 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006560513195140382\n",
      "2022-07-06 10:27:24,927 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:24,927 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006618813258114292\n",
      "2022-07-06 10:27:25,063 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 240\n",
      "2022-07-06 10:27:25,067 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:25,067 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006621737668612193\n",
      "2022-07-06 10:27:25,184 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 241\n",
      "2022-07-06 10:27:25,188 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:25,188 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006624506248279767\n",
      "2022-07-06 10:27:25,311 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 242\n",
      "2022-07-06 10:27:25,315 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:25,317 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006641624752034302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:25,469 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:25,470 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006629328404110196\n",
      "2022-07-06 10:27:25,606 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 243\n",
      "2022-07-06 10:27:25,610 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:25,610 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006628817167614285\n",
      "2022-07-06 10:27:25,736 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 244\n",
      "2022-07-06 10:27:25,742 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:25,742 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006628667259810669\n",
      "2022-07-06 10:27:25,878 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 245\n",
      "2022-07-06 10:27:25,884 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:25,884 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066262883014752165\n",
      "2022-07-06 10:27:26,011 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 246\n",
      "2022-07-06 10:27:26,016 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:26,017 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006598381648619102\n",
      "2022-07-06 10:27:26,150 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:26,151 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006622108613937032\n",
      "2022-07-06 10:27:26,281 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 247\n",
      "2022-07-06 10:27:26,284 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:26,284 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006624410557077591\n",
      "2022-07-06 10:27:26,402 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 248\n",
      "2022-07-06 10:27:26,405 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:26,406 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006627606539874664\n",
      "2022-07-06 10:27:26,513 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 249\n",
      "2022-07-06 10:27:26,517 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:26,517 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006629227638785973\n",
      "2022-07-06 10:27:26,655 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 250\n",
      "2022-07-06 10:27:26,659 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:26,660 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006630305576280471\n",
      "2022-07-06 10:27:26,778 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 251\n",
      "2022-07-06 10:27:26,781 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:26,782 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006629796846367739\n",
      "2022-07-06 10:27:26,890 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 252\n",
      "2022-07-06 10:27:26,894 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:26,895 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006833047584792751\n",
      "2022-07-06 10:27:27,030 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,031 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00665058722666157\n",
      "2022-07-06 10:27:27,127 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,128 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006632355915542231\n",
      "2022-07-06 10:27:27,230 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 253\n",
      "2022-07-06 10:27:27,233 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,234 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006628502731517098\n",
      "2022-07-06 10:27:27,335 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 254\n",
      "2022-07-06 10:27:27,338 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,338 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006630632589084048\n",
      "2022-07-06 10:27:27,463 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 255\n",
      "2022-07-06 10:27:27,466 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,467 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006570134215441555\n",
      "2022-07-06 10:27:27,564 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,564 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006624963293588434\n",
      "2022-07-06 10:27:27,670 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 256\n",
      "2022-07-06 10:27:27,674 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,675 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006625535592740593\n",
      "2022-07-06 10:27:27,810 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 257\n",
      "2022-07-06 10:27:27,814 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,815 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006627849955480894\n",
      "2022-07-06 10:27:27,922 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 258\n",
      "2022-07-06 10:27:27,925 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:27,926 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006629698004539454\n",
      "2022-07-06 10:27:28,027 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 259\n",
      "2022-07-06 10:27:28,030 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:28,031 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006633358597342964\n",
      "2022-07-06 10:27:28,148 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 260\n",
      "2022-07-06 10:27:28,153 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:28,153 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006628901763643747\n",
      "2022-07-06 10:27:28,250 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 261\n",
      "2022-07-06 10:27:28,253 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:28,253 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006632203794930804\n",
      "2022-07-06 10:27:28,381 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 262\n",
      "2022-07-06 10:27:28,385 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:28,386 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006625322152609067\n",
      "2022-07-06 10:27:28,483 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 263\n",
      "2022-07-06 10:27:28,487 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:28,487 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006621170409996491\n",
      "2022-07-06 10:27:28,584 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 264\n",
      "2022-07-06 10:27:28,587 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:28,588 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006620565473181112\n",
      "2022-07-06 10:27:28,686 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 265\n",
      "2022-07-06 10:27:28,689 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:28,690 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006403475944849951\n",
      "2022-07-06 10:27:28,795 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:28,796 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006573289038481429\n",
      "2022-07-06 10:27:28,940 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:28,941 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006616140762381777\n",
      "2022-07-06 10:27:29,084 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 266\n",
      "2022-07-06 10:27:29,089 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:29,090 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066232824695108316\n",
      "2022-07-06 10:27:29,228 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 267\n",
      "2022-07-06 10:27:29,233 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:29,233 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066229956185345044\n",
      "2022-07-06 10:27:29,371 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 268\n",
      "2022-07-06 10:27:29,374 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:29,375 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006854714787223417\n",
      "2022-07-06 10:27:29,511 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:29,512 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006630898283815815\n",
      "2022-07-06 10:27:29,638 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 269\n",
      "2022-07-06 10:27:29,641 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:29,642 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006628431769910233\n",
      "2022-07-06 10:27:29,772 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 270\n",
      "2022-07-06 10:27:29,776 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:29,777 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066260095984245\n",
      "2022-07-06 10:27:29,911 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 271\n",
      "2022-07-06 10:27:29,914 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:29,915 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066223009493907685\n",
      "2022-07-06 10:27:30,020 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 272\n",
      "2022-07-06 10:27:30,023 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:30,023 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00661889813496696\n",
      "2022-07-06 10:27:30,151 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 273\n",
      "2022-07-06 10:27:30,160 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:30,160 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006618629126191714\n",
      "2022-07-06 10:27:30,296 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 274\n",
      "2022-07-06 10:27:30,300 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:30,300 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00660880518525239\n",
      "2022-07-06 10:27:30,398 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:30,399 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006615640018275813\n",
      "2022-07-06 10:27:30,537 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 275\n",
      "2022-07-06 10:27:30,541 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:30,542 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006620503151436598\n",
      "2022-07-06 10:27:30,677 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 276\n",
      "2022-07-06 10:27:30,680 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:30,681 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006640744294421898\n",
      "2022-07-06 10:27:30,810 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:30,811 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006627638184301577\n",
      "2022-07-06 10:27:30,923 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 277\n",
      "2022-07-06 10:27:30,926 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:30,928 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006626370716137573\n",
      "2022-07-06 10:27:31,025 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 278\n",
      "2022-07-06 10:27:31,033 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:31,033 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006622144601202712\n",
      "2022-07-06 10:27:31,167 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:31,168 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006625229523144753\n",
      "2022-07-06 10:27:31,274 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 279\n",
      "2022-07-06 10:27:31,277 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 10:27:31,277 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006780021484170228\n",
      "2022-07-06 10:27:31,374 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:31,375 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006631029797837699\n",
      "2022-07-06 10:27:31,488 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 280\n",
      "2022-07-06 10:27:31,492 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:31,493 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066299800764004066\n",
      "2022-07-06 10:27:31,638 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 281\n",
      "2022-07-06 10:27:31,642 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:31,642 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066211586583111584\n",
      "2022-07-06 10:27:31,773 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 282\n",
      "2022-07-06 10:27:31,777 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:31,778 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00662037523515648\n",
      "2022-07-06 10:27:31,905 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 283\n",
      "2022-07-06 10:27:31,908 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:31,909 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006626449487961438\n",
      "2022-07-06 10:27:32,039 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 284\n",
      "2022-07-06 10:27:32,042 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:32,043 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006624810632037882\n",
      "2022-07-06 10:27:32,156 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 285\n",
      "2022-07-06 10:27:32,160 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:32,160 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066240456019284796\n",
      "2022-07-06 10:27:32,290 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 286\n",
      "2022-07-06 10:27:32,293 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:32,294 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.0066211453000358895\n",
      "2022-07-06 10:27:32,396 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 287\n",
      "2022-07-06 10:27:32,400 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:32,400 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.00662955873238671\n",
      "2022-07-06 10:27:32,535 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:32,536 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006625396820963865\n",
      "2022-07-06 10:27:32,671 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 288\n",
      "2022-07-06 10:27:32,674 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:32,675 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006622047960831041\n",
      "2022-07-06 10:27:32,802 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 289\n",
      "2022-07-06 10:27:32,805 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:32,806 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006622253846939442\n",
      "2022-07-06 10:27:32,916 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 290\n",
      "2022-07-06 10:27:32,921 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:32,921 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006758217061105706\n",
      "2022-07-06 10:27:33,050 | gradvi.models.linear_model               | DEBUG   | Calculating reparametrized Linear Model objective with ash_scaled prior\n",
      "2022-07-06 10:27:33,050 | gradvi.models.linear_model               | DEBUG   | Residual variance = 0.006624814641855403\n",
      "2022-07-06 10:27:33,148 | gradvi.inference.linear_regression       | DEBUG   | Callback iteration 291\n",
      "2022-07-06 10:27:33,176 | gradvi.inference.linear_regression       | DEBUG   | Terminated at iteration 291.\n",
      "2022-07-06 10:27:33,176 | gradvi.inference.linear_regression       | DEBUG   | Number of iterations:     291\n",
      "2022-07-06 10:27:33,177 | gradvi.inference.linear_regression       | DEBUG   | Number of callbacks:      291\n",
      "2022-07-06 10:27:33,177 | gradvi.inference.linear_regression       | DEBUG   | Number of function calls: 400\n"
     ]
    }
   ],
   "source": [
    "gv1.fit(data['X'], data['y'], prior, s2_init = 1.)\n",
    "#print(gv1.residual_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "213d5585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv1.niter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c61d5187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(data['beta'], gv1.coef, label = 'GradVI')\n",
    "ax1.scatter(data['beta'], np.squeeze(res_cavi['beta_est']), label = 'CAVI')\n",
    "ax1.legend()\n",
    "mpl_utils.plot_diag(ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e09514",
   "metadata": {},
   "source": [
    "## Compare DSC result with GradVI result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "60d39a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(gv1.coef, res['beta_est'])\n",
    "mpl_utils.plot_diag(ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9c699a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smbase': 2.718281828459045,\n",
       " 'sk': array([0.        , 0.03526492, 0.07177346, 0.10956947, 0.14869835,\n",
       "        0.18920712, 0.23114441, 0.27456063, 0.31950791, 0.36604026,\n",
       "        0.41421356, 0.4640857 , 0.51571657, 0.5691682 , 0.62450479,\n",
       "        0.68179283, 0.74110113, 0.80250093, 0.86606598, 0.93187266]),\n",
       " 'w': array([9.99999306e-01, 3.54315796e-07, 9.43456734e-08, 4.16160155e-08,\n",
       "        2.62535905e-08, 1.98261151e-08, 1.64713080e-08, 1.44588874e-08,\n",
       "        1.31367735e-08, 1.22137780e-08, 1.15406810e-08, 1.10320434e-08,\n",
       "        1.06352909e-08, 1.03167452e-08, 1.00542837e-08, 9.83316637e-09,\n",
       "        9.64383705e-09, 9.48061936e-09, 9.33956072e-09, 9.21198087e-09]),\n",
       " 'wmod': array([13.9883662 , -0.86471035, -2.18793353, -3.00641386, -3.46709618,\n",
       "        -3.74789893, -3.93327899, -4.06358968, -4.15948351, -4.23233428,\n",
       "        -4.28902068, -4.33409487, -4.37072114, -4.40113063, -4.42690016,\n",
       "        -4.44913795, -4.46857988, -4.4856493 , -4.50063972, -4.51439404]),\n",
       " 'w_init': array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "        0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]),\n",
       " 'wmod_init': array([-2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207]),\n",
       " 'is_scaled': True}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['model']['prior']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "27847e7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "_dj :\n",
      "GradVI: [500. 500. 500. ... 500. 500. 500.]\n",
      "DSC:    [500. 500. 500. ... 500. 500. 500.]\n",
      "========\n",
      "_init_params :\n",
      "GradVI: (array([0., 0., 0., ..., 0., 0., 0.]), array([-2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207]), 1.0)\n",
      "DSC:    (array([0., 0., 0., ..., 0., 0., 0.]), array([-2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207]), 0.0014724179775473531)\n",
      "========\n",
      "_invert_method :\n",
      "GradVI: None\n",
      "DSC:    None\n",
      "========\n",
      "_invert_options :\n",
      "GradVI: {}\n",
      "DSC:    {}\n",
      "========\n",
      "_is_debug :\n",
      "GradVI: True\n",
      "DSC:    False\n",
      "========\n",
      "_is_elbo_calc :\n",
      "GradVI: False\n",
      "DSC:    False\n",
      "========\n",
      "_is_intercept :\n",
      "GradVI: True\n",
      "DSC:    True\n",
      "========\n",
      "_method :\n",
      "GradVI: l-bfgs-b\n",
      "DSC:    l-bfgs-b\n",
      "========\n",
      "_nclbk :\n",
      "GradVI: 291\n",
      "DSC:    362\n",
      "========\n",
      "_objtype :\n",
      "GradVI: reparametrize\n",
      "DSC:    reparametrize\n",
      "========\n",
      "_opts :\n",
      "GradVI: {'maxiter': 2000, 'disp': False, 'ftol': 1e-09, 'gtol': 1e-09, 'maxfun': 20000}\n",
      "DSC:    {'maxiter': 2000, 'disp': False, 'ftol': 1e-09, 'gtol': 1e-09, 'maxfun': 20000}\n",
      "========\n",
      "coef :\n",
      "GradVI: [-1.56049650e-06 -2.60827927e-06  1.20763682e-05 ...  1.32323309e-05\n",
      "  1.60520867e-06  9.62051554e-07]\n",
      "DSC:    [-5.47594726e-09 -7.22650488e-09  2.03669351e-10 ...  8.80410184e-09\n",
      "  6.38169391e-10 -4.35792412e-09]\n",
      "========\n",
      "elbo_path :\n",
      "GradVI: [3354.15074569  311.07691565 -334.7033187  -343.59154643 -344.34301729\n",
      " -344.96367751 -344.9892734  -344.98998123 -345.00367116 -345.04473612\n",
      " -345.07310539 -345.0873921  -345.092476   -345.09488098 -345.09586057\n",
      " -345.09615165 -345.09621773 -427.79913721 -432.92739061 -435.11549853\n",
      " -443.55930265 -501.39966205 -502.75849395 -508.91269786 -511.41773398\n",
      " -517.94732856 -519.80864998 -520.02499208 -521.46706825 -521.87307394\n",
      " -522.33935947 -522.56817192 -522.76342217 -522.88245778 -522.96173566\n",
      " -522.96874147 -523.02536373 -523.0683197  -523.10584422 -523.12297308\n",
      " -523.16219713 -523.22384281 -523.23202325 -523.24381558 -523.24842751\n",
      " -523.25804263 -523.25932389 -523.26628286 -523.2676012  -523.27276916\n",
      " -523.28029538 -523.31589117 -523.39464205 -523.44925191 -523.48072776\n",
      " -523.51835578 -523.55206924 -523.55869018 -523.58301006 -523.63565656\n",
      " -523.65446606 -523.68923689 -523.72048445 -523.74573972 -523.76809332\n",
      " -523.78860272 -523.80320663 -523.81657043 -523.83918277 -523.86416489\n",
      " -523.87051656 -523.89245396 -523.90136184 -523.90750872 -523.9133937\n",
      " -523.92302034 -523.94039506 -523.96389771 -523.99372968 -524.010212\n",
      " -524.01702808 -524.02258261 -524.02468551 -524.03161874 -524.04487697\n",
      " -524.06240933 -524.07297916 -524.0871161  -524.10593154 -524.13141263\n",
      " -524.13300961 -524.15402943 -524.17046698 -524.17331315 -524.17701399\n",
      " -524.18495126 -524.19942736 -524.2195626  -524.2421964  -524.26660947\n",
      " -524.28927483 -524.29945391 -524.30956819 -524.31603364 -524.31896528\n",
      " -524.32899968 -524.34080138 -524.35312214 -524.36246599 -524.36759022\n",
      " -524.40003403 -524.4077587  -524.42268    -524.42588307 -524.43193574\n",
      " -524.43584603 -524.4370796  -524.43916213 -524.43978651 -524.44089602\n",
      " -524.44399863 -524.44886221 -524.45053339 -524.45623487 -524.46436822\n",
      " -524.47111951 -524.48607893 -524.48710143 -524.49019084 -524.49362242\n",
      " -524.50398667 -524.50636117 -524.50878774 -524.51246773 -524.51788678\n",
      " -524.52641484 -524.53885197 -524.54575924 -524.5500294  -524.55465138\n",
      " -524.55564844 -524.55718699 -524.55854437 -524.56063499 -524.5652086\n",
      " -524.57038623 -524.57999683 -524.58506383 -524.58861855 -524.59221889\n",
      " -524.59409939 -524.59701465 -524.60105572 -524.60526776 -524.60733888\n",
      " -524.607796   -524.60827084 -524.60913227 -524.61295852 -524.62284772\n",
      " -524.63221755 -524.63995207 -524.64190558 -524.64717734 -524.65100493\n",
      " -524.65704544 -524.66256351 -524.66932353 -524.67108606 -524.68661528\n",
      " -524.69845982 -524.70984139 -524.72275026 -524.73208691 -524.73225267\n",
      " -524.73623739 -524.7379343  -524.74105648 -524.74275832 -524.74388011\n",
      " -524.74634949 -524.74978549 -524.75309803 -524.7619263  -524.76726713\n",
      " -524.76766    -524.77010394 -524.77893027 -524.78499025 -524.78764908\n",
      " -524.79140475 -524.79591646 -524.79828453 -524.80245814 -524.8064014\n",
      " -524.81279166 -524.81405336 -524.81773549 -524.82048143 -524.82098264\n",
      " -524.8213974  -524.82256596 -524.82329892 -524.82381514 -524.82921598\n",
      " -524.83150658 -524.83399322 -524.83410003 -524.83476985 -524.83510237\n",
      " -524.83540802 -524.83709142 -524.83844553 -524.84186946 -524.84558905\n",
      " -524.84758889 -524.85008813 -524.85258833 -524.85268558 -524.85412929\n",
      " -524.85540846 -524.85562913 -524.85613499 -524.85652731 -524.85699805\n",
      " -524.8573858  -524.85847787 -524.86195483 -524.8662503  -524.86658942\n",
      " -524.86808736 -524.86847569 -524.86907851 -524.87049961 -524.87281922\n",
      " -524.87411121 -524.87509149 -524.87569264 -524.87587432 -524.87647347\n",
      " -524.87763038 -524.87859407 -524.87874945 -524.87899717 -524.87947497\n",
      " -524.88294153 -524.88308965 -524.8839783  -524.88439044 -524.8846613\n",
      " -524.88507769 -524.88630434 -524.88640796 -524.88729035 -524.88771407\n",
      " -524.88791965 -524.88801622 -524.88829836 -524.88888833 -524.88973728\n",
      " -524.891081   -524.89208512 -524.89331997 -524.89436195 -524.89548249\n",
      " -524.89572106 -524.89711145 -524.8977787  -524.89796074 -524.8981789\n",
      " -524.89850009 -524.89911925 -524.89993295 -524.90086001 -524.90162673\n",
      " -524.90420938 -524.9050331  -524.90588881 -524.90700054 -524.90715251\n",
      " -524.90756152 -524.90968064 -524.91014256 -524.91054005 -524.91101221\n",
      " -524.91172883 -524.91368527 -524.91427157 -524.91494652 -524.91521531\n",
      " -524.91524006]\n",
      "DSC:    [ 1.50121696e+04  1.17179857e+04  1.10362981e+04  1.10338192e+04\n",
      "  1.09968936e+04  1.09892885e+04  1.09725328e+04  1.08869517e+04\n",
      "  1.08306991e+04  1.08223418e+04  1.08198562e+04  1.08113822e+04\n",
      "  1.08084336e+04  1.08082683e+04  1.08078789e+04  1.08065638e+04\n",
      "  1.08040051e+04  1.07997518e+04  1.07823937e+04  1.07503038e+04\n",
      "  1.07202492e+04  1.06659765e+04  1.06632775e+04  1.05588459e+04\n",
      "  1.05072465e+04  1.04083990e+04  1.02749142e+04  9.79835487e+03\n",
      "  9.34422302e+03  9.17219250e+03  8.90258958e+03  8.68088872e+03\n",
      "  8.35126914e+03  7.94431473e+03  7.39363522e+03  5.74703504e+03\n",
      "  4.57491600e+03  3.73681355e+03  2.98812168e+03  2.62117234e+03\n",
      "  1.77368422e+03  1.22481498e+03  9.63751795e+02  6.93949062e+02\n",
      "  5.98688999e+02  5.54275987e+02  5.09444975e+02  4.79497561e+02\n",
      "  4.72980070e+02  4.48608415e+02  4.27164482e+02  4.13896797e+02\n",
      "  3.97007092e+02  3.64480907e+02  3.40187868e+02  3.08317634e+02\n",
      "  2.65511950e+02  2.51893591e+02  2.35881989e+02  2.15685589e+02\n",
      "  1.96489348e+02  1.85535843e+02  1.72259367e+02  1.64157424e+02\n",
      "  1.43273025e+02  1.24500171e+02  1.16414116e+02  1.01962918e+02\n",
      "  9.55669208e+01  8.64963837e+01  8.21424786e+01  6.68929701e+01\n",
      "  5.69525752e+01  4.23185358e+01  3.95436251e+01  2.70493945e+01\n",
      "  1.96153414e+01  6.99554730e+00  3.09330355e+00 -5.30132125e+00\n",
      " -1.10013720e+01 -2.95338283e+01 -3.54066031e+01 -4.61536655e+01\n",
      " -5.53414240e+01 -6.54729242e+01 -7.18443475e+01 -8.34766897e+01\n",
      " -9.60893212e+01 -1.01663427e+02 -1.04711906e+02 -1.07549370e+02\n",
      " -1.10020080e+02 -1.16082363e+02 -1.26399290e+02 -1.34442929e+02\n",
      " -1.43976460e+02 -1.51374990e+02 -1.53557839e+02 -1.56460921e+02\n",
      " -1.58847847e+02 -1.60158676e+02 -1.66360257e+02 -1.71549749e+02\n",
      " -1.76667539e+02 -1.80623010e+02 -1.87638273e+02 -1.97912263e+02\n",
      " -1.98294863e+02 -2.05232984e+02 -2.17046669e+02 -2.18603429e+02\n",
      " -2.24343297e+02 -2.26193430e+02 -2.31097479e+02 -2.39881647e+02\n",
      " -2.46516923e+02 -2.52772499e+02 -2.56304978e+02 -2.57488763e+02\n",
      " -2.64982997e+02 -2.66317786e+02 -2.74365934e+02 -2.78331651e+02\n",
      " -2.80729019e+02 -2.83060329e+02 -2.83823663e+02 -2.88487852e+02\n",
      " -2.94272848e+02 -3.00085811e+02 -3.06694152e+02 -3.17284920e+02\n",
      " -3.24866932e+02 -3.27900326e+02 -3.29295786e+02 -3.30558984e+02\n",
      " -3.31356425e+02 -3.34162120e+02 -3.38225280e+02 -3.45101380e+02\n",
      " -3.49712929e+02 -3.52851669e+02 -3.56640802e+02 -3.57635845e+02\n",
      " -3.59222803e+02 -3.61894379e+02 -3.64293788e+02 -3.66384567e+02\n",
      " -3.70734017e+02 -3.73643691e+02 -3.83712451e+02 -3.88982985e+02\n",
      " -3.90839330e+02 -3.92527241e+02 -3.95056312e+02 -3.96790129e+02\n",
      " -4.00864303e+02 -4.04691095e+02 -4.06555890e+02 -4.07030620e+02\n",
      " -4.10305212e+02 -4.16847307e+02 -4.18327736e+02 -4.19659278e+02\n",
      " -4.20968934e+02 -4.21722291e+02 -4.23079568e+02 -4.24240027e+02\n",
      " -4.25352898e+02 -4.26875766e+02 -4.29274515e+02 -4.29661512e+02\n",
      " -4.32179972e+02 -4.32850356e+02 -4.33992443e+02 -4.34908612e+02\n",
      " -4.39604535e+02 -4.40923113e+02 -4.42242837e+02 -4.47879536e+02\n",
      " -4.52907817e+02 -4.56900628e+02 -4.57925252e+02 -4.62112536e+02\n",
      " -4.63022475e+02 -4.63231839e+02 -4.64258403e+02 -4.64993069e+02\n",
      " -4.67138186e+02 -4.71844020e+02 -4.73419737e+02 -4.74347974e+02\n",
      " -4.74599556e+02 -4.75518624e+02 -4.76019574e+02 -4.77726184e+02\n",
      " -4.79026400e+02 -4.81217734e+02 -4.82896564e+02 -4.85250495e+02\n",
      " -4.86638140e+02 -4.87279430e+02 -4.87725227e+02 -4.88630183e+02\n",
      " -4.88803520e+02 -4.90186772e+02 -4.91548439e+02 -4.93484409e+02\n",
      " -4.93940609e+02 -4.97572538e+02 -5.00171106e+02 -5.02223481e+02\n",
      " -5.03496886e+02 -5.05123351e+02 -5.05379203e+02 -5.05908823e+02\n",
      " -5.06772566e+02 -5.07132716e+02 -5.07732733e+02 -5.08686775e+02\n",
      " -5.09125898e+02 -5.10518731e+02 -5.11542550e+02 -5.12194047e+02\n",
      " -5.12456229e+02 -5.13145171e+02 -5.14622994e+02 -5.14860496e+02\n",
      " -5.15067256e+02 -5.15371671e+02 -5.15473420e+02 -5.15800540e+02\n",
      " -5.15917931e+02 -5.16324573e+02 -5.16939147e+02 -5.17190135e+02\n",
      " -5.17280733e+02 -5.17362198e+02 -5.17417207e+02 -5.17430706e+02\n",
      " -5.17535399e+02 -5.17573775e+02 -5.17642798e+02 -5.17775504e+02\n",
      " -5.17875186e+02 -5.18036154e+02 -5.18104093e+02 -5.18181493e+02\n",
      " -5.18253101e+02 -5.18335782e+02 -5.18389677e+02 -5.18437721e+02\n",
      " -5.18649466e+02 -5.18665088e+02 -5.18851542e+02 -5.19063240e+02\n",
      " -5.19139335e+02 -5.19145391e+02 -5.19152036e+02 -5.19160436e+02\n",
      " -5.19165740e+02 -5.19170541e+02 -5.19172559e+02 -5.19174291e+02\n",
      " -5.19176112e+02 -5.19177125e+02 -5.19177731e+02 -5.19178622e+02\n",
      " -5.19189466e+02 -5.19220610e+02 -5.19263883e+02 -5.19272798e+02\n",
      " -5.19283874e+02 -5.19292592e+02 -5.19298060e+02 -5.19302301e+02\n",
      " -5.19302956e+02 -5.19303603e+02 -5.19303802e+02 -5.19304850e+02\n",
      " -5.19307349e+02 -5.19311583e+02 -5.19320798e+02 -5.19329591e+02\n",
      " -5.19332968e+02 -5.19335040e+02 -5.19335276e+02 -5.19336191e+02\n",
      " -5.19337620e+02 -5.19337826e+02 -5.19337969e+02 -5.19338334e+02\n",
      " -5.19339076e+02 -5.19340905e+02 -5.19346377e+02 -5.19350020e+02\n",
      " -5.19350753e+02 -5.19352581e+02 -5.19354670e+02 -5.19355921e+02\n",
      " -5.19357168e+02 -5.19357723e+02 -5.19358548e+02 -5.19359071e+02\n",
      " -5.19359361e+02 -5.19359415e+02 -5.19359514e+02 -5.19359632e+02\n",
      " -5.19359951e+02 -5.19360786e+02 -5.19361871e+02 -5.19362487e+02\n",
      " -5.19362619e+02 -5.19363150e+02 -5.19363689e+02 -5.19365034e+02\n",
      " -5.19368447e+02 -5.19369068e+02 -5.19369245e+02 -5.19372455e+02\n",
      " -5.19373855e+02 -5.19375059e+02 -5.19376624e+02 -5.19376937e+02\n",
      " -5.19377079e+02 -5.19377132e+02 -5.19377309e+02 -5.19377583e+02\n",
      " -5.19377883e+02 -5.19377995e+02 -5.19378356e+02 -5.19378550e+02\n",
      " -5.19379060e+02 -5.19379254e+02 -5.19380020e+02 -5.19383572e+02\n",
      " -5.19386226e+02 -5.19393912e+02 -5.19396594e+02 -5.19403951e+02\n",
      " -5.19405975e+02 -5.19415250e+02 -5.19419580e+02 -5.19441830e+02\n",
      " -5.19444753e+02 -5.19446535e+02 -5.19447171e+02 -5.19448004e+02\n",
      " -5.19448747e+02 -5.19451204e+02 -5.19451541e+02 -5.19452717e+02\n",
      " -5.19452766e+02 -5.19453016e+02 -5.19453146e+02 -5.19453221e+02\n",
      " -5.19453669e+02 -5.19454349e+02 -5.19454949e+02 -5.19455239e+02\n",
      " -5.19455297e+02 -5.19455326e+02]\n",
      "========\n",
      "fitobj :\n",
      "GradVI:       fun: -31597.95573217031\n",
      " hess_inv: <10021x10021 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 2.46362410e-03,  4.62077839e-03,  5.30064769e-02, ...,\n",
      "       -8.63312708e-02, -8.87581944e-02,  7.73626264e+00])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 400\n",
      "      nit: 291\n",
      "     njev: 400\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-2.93402406e-03, -4.19106877e-03,  8.00422582e-03, ...,\n",
      "       -4.39437204e+00, -4.41595892e+00,  6.62481464e-03])\n",
      "DSC:          fun: -31592.49581824498\n",
      " hess_inv: <10021x10021 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-9.70302075e-04, -1.12593395e-03, -1.00165772e-04, ...,\n",
      "       -1.39282222e-01, -1.41984149e-01,  8.91760951e+00])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 590\n",
      "      nit: 362\n",
      "     njev: 590\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-7.65812771e-03, -8.17571977e-03,  1.08438924e-03, ...,\n",
      "       -4.50063972e+00, -4.51439404e+00,  6.79977278e-03])\n",
      "========\n",
      "fun :\n",
      "GradVI: -31597.95573217031\n",
      "DSC:    -31592.49581824498\n",
      "========\n",
      "grad :\n",
      "GradVI: [ 2.46362410e-03  4.62077839e-03  5.30064769e-02 ... -8.63312708e-02\n",
      " -8.87581944e-02  7.73626264e+00]\n",
      "DSC:    [-9.70302075e-04 -1.12593395e-03 -1.00165772e-04 ... -1.39282222e-01\n",
      " -1.41984149e-01  8.91760951e+00]\n",
      "========\n",
      "intercept :\n",
      "GradVI: 0.00822464490122526\n",
      "DSC:    0.00822464490122526\n",
      "========\n",
      "nfev :\n",
      "GradVI: 400\n",
      "DSC:    590\n",
      "========\n",
      "niter :\n",
      "GradVI: 291\n",
      "DSC:    362\n",
      "========\n",
      "njev :\n",
      "GradVI: 400\n",
      "DSC:    590\n",
      "========\n",
      "obj_path :\n",
      "GradVI: [-27718.889746418925, -30761.96357646417, -31407.743810814638, -31416.63203854544, -31417.383509404062, -31418.00416961823, -31418.029765509906, -31418.030473345763, -31418.044163269748, -31418.085228232816, -31418.11359750555, -31418.12788420704, -31418.13296810895, -31418.135373089117, -31418.13635268418, -31418.136643765294, -31418.136709837654, -31500.83962932017, -31505.967882720135, -31508.15599063802, -31516.599794759743, -31574.44015415791, -31575.798986059923, -31581.953189969325, -31584.458226090712, -31590.987820672424, -31592.849142086743, -31593.06548419164, -31594.507560364167, -31594.913566054805, -31595.379851580357, -31595.608664032377, -31595.80391428278, -31595.922949887456, -31596.00222776711, -31596.009233585748, -31596.065855844197, -31596.10881181032, -31596.146336334416, -31596.163465190144, -31596.2026892387, -31596.264334917167, -31596.272515357137, -31596.28430769327, -31596.288919623315, -31596.29853474026, -31596.29981600558, -31596.30677497114, -31596.308093307245, -31596.3132612758, -31596.32078748683, -31596.356383278006, -31596.435134165935, -31596.489744021157, -31596.52121987157, -31596.558847894405, -31596.592561355035, -31596.59918229142, -31596.623502175607, -31596.67614866955, -31596.69495817343, -31596.72972899597, -31596.76097656128, -31596.786231831284, -31596.808585431285, -31596.829094835208, -31596.84369873799, -31596.85706254494, -31596.879674878488, -31596.90465700382, -31596.91100866794, -31596.932946069734, -31596.941853952067, -31596.948000827957, -31596.95388581563, -31596.963512446884, -31596.980887173868, -31597.00438982232, -31597.034221795686, -31597.050704107096, -31597.057520190596, -31597.0630747259, -31597.065177623463, -31597.07211084701, -31597.085369080483, -31597.102901445935, -31597.113471273486, -31597.127608210867, -31597.146423648053, -31597.17190473628, -31597.173501718957, -31597.194521541693, -31597.210959095726, -31597.21380526103, -31597.217506100562, -31597.225443371943, -31597.23991946829, -31597.260054715487, -31597.282688508276, -31597.307101582363, -31597.329766941286, -31597.33994601851, -31597.350060304074, -31597.356525747666, -31597.3594573935, -31597.369491790167, -31597.38129348786, -31597.39361424667, -31597.402958099883, -31597.408082330105, -31597.440526139242, -31597.44825080962, -31597.463172114505, -31597.466375178792, -31597.472427853034, -31597.47633814437, -31597.477571711155, -31597.479654242186, -31597.480278619732, -31597.481388130618, -31597.48449073922, -31597.48935432352, -31597.491025497708, -31597.49672698404, -31597.504860329947, -31597.511611619153, -31597.526571042057, -31597.527593545397, -31597.530682948523, -31597.534114528295, -31597.544478779695, -31597.546853279466, -31597.549279847713, -31597.552959844226, -31597.558378888163, -31597.566906952234, -31597.579344084144, -31597.586251354056, -31597.5905215121, -31597.595143494094, -31597.596140553702, -31597.597679103717, -31597.599036482978, -31597.601127105, -31597.605700709042, -31597.610878343134, -31597.62048893841, -31597.625555937168, -31597.629110658665, -31597.632711000624, -31597.634591505957, -31597.63750676337, -31597.641547826905, -31597.645759872394, -31597.647830993777, -31597.648288109267, -31597.648762946148, -31597.64962437647, -31597.653450629616, -31597.663339830513, -31597.672709663726, -31597.68044418309, -31597.68239768981, -31597.6876694511, -31597.69149704068, -31597.697537553453, -31597.703055616934, -31597.709815641276, -31597.71157816597, -31597.727107391696, -31597.738951928033, -31597.750333498785, -31597.763242371067, -31597.772579016448, -31597.772744785412, -31597.776729500816, -31597.778426408186, -31597.78154859555, -31597.783250435754, -31597.784372220103, -31597.786841597394, -31597.790277601103, -31597.793590142814, -31597.802418406798, -31597.80775924094, -31597.808152106056, -31597.810596049443, -31597.819422377186, -31597.825482358447, -31597.82814118805, -31597.831896863077, -31597.836408575837, -31597.83877663682, -31597.842950254846, -31597.846893509537, -31597.853283771256, -31597.854545466733, -31597.85822760391, -31597.860973538995, -31597.861474747653, -31597.86188951043, -31597.86305807397, -31597.863791028787, -31597.864307251133, -31597.869708093196, -31597.871998687682, -31597.874485335884, -31597.87459213608, -31597.875261961894, -31597.875594483703, -31597.875900134095, -31597.877583532274, -31597.878937638823, -31597.88236156728, -31597.886081160075, -31597.888081004094, -31597.890580242194, -31597.893080442715, -31597.89317768903, -31597.89462139843, -31597.895900573927, -31597.896121238, -31597.896627098526, -31597.897019420685, -31597.89749016025, -31597.89787791445, -31597.89896998355, -31597.902446945, -31597.90674240753, -31597.907081526377, -31597.908579470048, -31597.908967803978, -31597.909570620097, -31597.910991725257, -31597.913311330136, -31597.914603318288, -31597.91558359767, -31597.916184752474, -31597.91636643394, -31597.916965584278, -31597.918122487135, -31597.919086175963, -31597.91924156478, -31597.9194892781, -31597.91996708264, -31597.92343363669, -31597.92358176589, -31597.924470409103, -31597.924882553387, -31597.92515341277, -31597.92556979868, -31597.926796450967, -31597.926900068593, -31597.92778246149, -31597.928206177814, -31597.92841176418, -31597.92850832917, -31597.928790467173, -31597.929380442394, -31597.930229387417, -31597.931573107442, -31597.932577232306, -31597.933812077456, -31597.93485405897, -31597.9359746037, -31597.93621317125, -31597.93760356276, -31597.93827080938, -31597.938452851857, -31597.93867101248, -31597.938992199954, -31597.93961136048, -31597.94042506135, -31597.94135211604, -31597.94211883791, -31597.944701489905, -31597.945525210092, -31597.946380924175, -31597.947492646235, -31597.947644623317, -31597.948053629698, -31597.950172754645, -31597.950634672274, -31597.951032164136, -31597.951504319903, -31597.952220944586, -31597.954177385276, -31597.954763683716, -31597.955438627676, -31597.95570742505, -31597.95573217031]\n",
      "DSC:    [-16060.870941294226, -19355.05481810791, -20036.742382557208, -20039.2213344973, -20076.14692236542, -20083.75198442083, -20100.507687637746, -20186.088786394852, -20242.34137103258, -20250.698672212733, -20253.184298558794, -20261.658335597018, -20264.60689280639, -20264.77220031343, -20265.16159122267, -20266.4766440509, -20269.035404392664, -20273.288715985276, -20290.646752389144, -20322.7367343842, -20352.791272798615, -20407.064002806623, -20409.76295278883, -20514.19464146717, -20565.79398122161, -20664.641447180366, -20798.12625304116, -21274.68562002364, -21728.8174764848, -21900.847990745548, -22170.450908367187, -22392.151767158983, -22721.771354256583, -23128.72576498641, -23679.405271541225, -25326.00545448104, -26498.124487172972, -27336.22693826902, -28084.918811687086, -28451.868147631092, -29299.35627180229, -29848.22551024614, -30109.28869713516, -30379.091430327553, -30474.351493581475, -30518.76450502892, -30563.595517520225, -30593.54293115934, -30600.060422234183, -30624.43207665533, -30645.87601014139, -30659.14369489262, -30676.033400492488, -30708.559585259758, -30732.85262427148, -30764.722857750527, -30807.528542567317, -30821.146901104137, -30837.158502637914, -30857.354903502575, -30876.551143763485, -30887.504648897295, -30900.781125114518, -30908.883067645187, -30929.76746752365, -30948.54032100796, -30956.626376366356, -30971.077574375933, -30977.473571333678, -30986.54410843244, -30990.898013476155, -31006.147522021438, -31016.087916865366, -31030.72195630608, -31033.496867033544, -31045.991097636117, -31053.42515070928, -31066.044944813577, -31069.947188562855, -31078.341813359904, -31084.041864106795, -31102.574320369, -31108.447095212665, -31119.19415756152, -31128.38191606842, -31138.513416292248, -31144.88483956705, -31156.51718176421, -31169.12981328015, -31174.70391956241, -31177.75239764937, -31180.589862147513, -31183.06057229894, -31189.122855275516, -31199.43978239261, -31207.483421339515, -31217.01695220588, -31224.415482002332, -31226.598330888963, -31229.501413524136, -31231.888339479086, -31233.19916766751, -31239.40074908879, -31244.59024126313, -31249.70803112638, -31253.663501711635, -31260.67876559472, -31270.952755044593, -31271.33535526563, -31278.273476602622, -31290.087161402367, -31291.643920870847, -31297.383789252697, -31299.233922414627, -31304.137971601023, -31312.92213896312, -31319.557414663817, -31325.812991033374, -31329.34546983967, -31330.52925493743, -31338.023489409337, -31339.35827780117, -31347.406426427257, -31351.37214294599, -31353.76951135205, -31356.100821272605, -31356.864155331008, -31361.52834444915, -31367.313340219604, -31373.12630357826, -31379.734644553027, -31390.325412226182, -31397.907423736648, -31400.94081785351, -31402.33627762087, -31403.59947567862, -31404.39691739506, -31407.202612214467, -31411.2657723923, -31418.1418718375, -31422.753420716126, -31425.892160638898, -31429.68129419189, -31430.676337174882, -31432.263295168195, -31434.934870621037, -31437.33427987024, -31439.4250590199, -31443.77450942574, -31446.684182999124, -31456.752943128195, -31462.023477587416, -31463.879821919127, -31465.567733300413, -31468.096804026467, -31469.830620800094, -31473.90479516372, -31477.731587244205, -31479.596382037562, -31480.071111890535, -31483.345703614876, -31489.887799239208, -31491.3682276985, -31492.699769759223, -31494.009426030534, -31494.76278266922, -31496.120060366968, -31497.28051866594, -31498.39339048718, -31499.91625851814, -31502.315007363348, -31502.70200363311, -31505.220464124915, -31505.890847763076, -31507.032935064017, -31507.949104051913, -31512.64502759028, -31513.96360475938, -31515.283329394526, -31520.920027671113, -31525.948309157342, -31529.94111993693, -31530.965744546673, -31535.153028223205, -31536.062966690428, -31536.272330665022, -31537.298895203552, -31538.03356158025, -31540.178677727577, -31544.88451188983, -31546.46022941032, -31547.388466412696, -31547.64004818196, -31548.559116088443, -31549.06006591861, -31550.76667567095, -31552.06689210086, -31554.258225750404, -31555.93705575505, -31558.290986983688, -31559.67863172471, -31560.319922069437, -31560.765719498475, -31561.670675161968, -31561.844012324906, -31563.227263894252, -31564.588930974758, -31566.524901275654, -31566.981100728597, -31570.613030232904, -31573.21159821908, -31575.263973153586, -31576.53737849639, -31578.163843013273, -31578.419694711087, -31578.949315206082, -31579.813058285392, -31580.173208061475, -31580.773225241734, -31581.72726731344, -31582.166389983897, -31583.55922308768, -31584.583042073435, -31585.234538646408, -31585.49672077858, -31586.18566321891, -31587.663485704143, -31587.900987698733, -31588.10774831772, -31588.412163597786, -31588.513911752583, -31588.84103164872, -31588.958423085573, -31589.36506508856, -31589.979638877914, -31590.23062681892, -31590.321225495132, -31590.40268973678, -31590.45769912104, -31590.471198526502, -31590.57589109642, -31590.614266884528, -31590.683290409776, -31590.815996046716, -31590.91567821204, -31591.076646275607, -31591.14458542908, -31591.22198477172, -31591.293593172213, -31591.376274118047, -31591.430169042327, -31591.478213589482, -31591.689957844355, -31591.705580349117, -31591.892034521654, -31592.103732391082, -31592.179827335334, -31592.18588261742, -31592.192528500975, -31592.200928217182, -31592.20623243183, -31592.211032953775, -31592.21305088923, -31592.21478346821, -31592.21660361402, -31592.217616981055, -31592.218223215496, -31592.219113993444, -31592.229958137243, -31592.26110203013, -31592.304375239553, -31592.313290418824, -31592.32436602087, -31592.333084316087, -31592.338552104295, -31592.342792735537, -31592.343447982832, -31592.3440953878, -31592.344294499188, -31592.345342442626, -31592.347840772833, -31592.352075091294, -31592.36128976035, -31592.370083332316, -31592.373460115206, -31592.375531855625, -31592.375767804733, -31592.37668342874, -31592.378112599254, -31592.3783184978, -31592.378460717846, -31592.37882629137, -31592.37956818982, -31592.381397267847, -31592.386869314825, -31592.390511732243, -31592.391245452345, -31592.393072959214, -31592.395162284152, -31592.39641296768, -31592.397659992654, -31592.398215161917, -31592.39904036282, -31592.399563169332, -31592.399853444844, -31592.39990745054, -31592.400006496242, -31592.400124261643, -31592.40044319381, -31592.40127812868, -31592.402363315872, -31592.402978651306, -31592.403110718045, -31592.403641675875, -31592.404181572623, -31592.40552578804, -31592.40893889885, -31592.409560504297, -31592.40973733978, -31592.412946819706, -31592.414347025144, -31592.41555139638, -31592.41711653964, -31592.4174287435, -31592.417571201884, -31592.41762451487, -31592.417801352436, -31592.418075361828, -31592.41837510779, -31592.418487487044, -31592.41884827234, -31592.419042584937, -31592.41955163284, -31592.419746133775, -31592.420512092696, -31592.42406396038, -31592.426718122242, -31592.43440431562, -31592.437086489263, -31592.444442894743, -31592.4464669842, -31592.455742460825, -31592.46007251345, -31592.4823219538, -31592.485245130283, -31592.487026611387, -31592.48766287052, -31592.488496430007, -31592.489238929807, -31592.49169604787, -31592.49203277567, -31592.4932093949, -31592.49325764623, -31592.49350850122, -31592.493638268777, -31592.493713115546, -31592.49416127682, -31592.494841124797, -31592.495440804516, -31592.495730925577, -31592.495789416676, -31592.49581824498]\n",
      "========\n",
      "prior :\n",
      "GradVI: <gradvi.priors.ash.Ash object at 0x7f5a97da1ee0>\n",
      "DSC:    {'smbase': 2.718281828459045, 'sk': array([0.        , 0.03526492, 0.07177346, 0.10956947, 0.14869835,\n",
      "       0.18920712, 0.23114441, 0.27456063, 0.31950791, 0.36604026,\n",
      "       0.41421356, 0.4640857 , 0.51571657, 0.5691682 , 0.62450479,\n",
      "       0.68179283, 0.74110113, 0.80250093, 0.86606598, 0.93187266]), 'w': array([9.99999306e-01, 3.54315796e-07, 9.43456734e-08, 4.16160155e-08,\n",
      "       2.62535905e-08, 1.98261151e-08, 1.64713080e-08, 1.44588874e-08,\n",
      "       1.31367735e-08, 1.22137780e-08, 1.15406810e-08, 1.10320434e-08,\n",
      "       1.06352909e-08, 1.03167452e-08, 1.00542837e-08, 9.83316637e-09,\n",
      "       9.64383705e-09, 9.48061936e-09, 9.33956072e-09, 9.21198087e-09]), 'wmod': array([13.9883662 , -0.86471035, -2.18793353, -3.00641386, -3.46709618,\n",
      "       -3.74789893, -3.93327899, -4.06358968, -4.15948351, -4.23233428,\n",
      "       -4.28902068, -4.33409487, -4.37072114, -4.40113063, -4.42690016,\n",
      "       -4.44913795, -4.46857988, -4.4856493 , -4.50063972, -4.51439404]), 'w_init': array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "       0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]), 'wmod_init': array([-2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
      "       -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207]), 'is_scaled': True}\n",
      "========\n",
      "residual_var :\n",
      "GradVI: 0.006624814641855403\n",
      "DSC:    0.006799772775137751\n",
      "========\n",
      "success :\n",
      "GradVI: True\n",
      "DSC:    True\n",
      "========\n",
      "theta :\n",
      "GradVI: [-0.00293402 -0.00419107  0.00800423 ...  0.00820358  0.00299821\n",
      "  0.0019634 ]\n",
      "DSC:    [-0.00765813 -0.00817572  0.00108439 ...  0.00852778  0.00290918\n",
      " -0.00721077]\n"
     ]
    }
   ],
   "source": [
    "for key, value in res['model'].items():\n",
    "    print(\"========\")\n",
    "    print(key, \":\")\n",
    "    #print ()\n",
    "    print ('GradVI:', getattr(gv1, key))\n",
    "    #print ()\n",
    "    print ('DSC:   ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a160ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smbase\n",
      "2.718281828459045\n",
      "2.718281828459045\n",
      "sk\n",
      "[0.         0.03526492 0.07177346 0.10956947 0.14869835 0.18920712\n",
      " 0.23114441 0.27456063 0.31950791 0.36604026 0.41421356 0.4640857\n",
      " 0.51571657 0.5691682  0.62450479 0.68179283 0.74110113 0.80250093\n",
      " 0.86606598 0.93187266]\n",
      "[0.         0.03526492 0.07177346 0.10956947 0.14869835 0.18920712\n",
      " 0.23114441 0.27456063 0.31950791 0.36604026 0.41421356 0.4640857\n",
      " 0.51571657 0.5691682  0.62450479 0.68179283 0.74110113 0.80250093\n",
      " 0.86606598 0.93187266]\n",
      "w\n",
      "[9.98425201e-01 1.28473350e-03 9.83884937e-05 3.92046458e-05\n",
      " 2.35031415e-05 1.69009773e-05 1.34335304e-05 1.13503387e-05\n",
      " 9.98211760e-06 9.02576630e-06 8.32564670e-06 7.79383029e-06\n",
      " 7.37720595e-06 7.04220048e-06 6.76685358e-06 6.53636753e-06\n",
      " 6.34048547e-06 6.17190098e-06 6.02527241e-06 5.89659938e-06]\n",
      "[9.99999306e-01 3.54315796e-07 9.43456734e-08 4.16160155e-08\n",
      " 2.62535905e-08 1.98261151e-08 1.64713080e-08 1.44588874e-08\n",
      " 1.31367735e-08 1.22137780e-08 1.15406810e-08 1.10320434e-08\n",
      " 1.06352909e-08 1.03167452e-08 1.00542837e-08 9.83316637e-09\n",
      " 9.64383705e-09 9.48061936e-09 9.33956072e-09 9.21198087e-09]\n",
      "wmod\n",
      "[ 7.62359978  0.96797185 -1.60141087 -2.52153948 -3.03320064 -3.36296329\n",
      " -3.59258089 -3.76108715 -3.88953948 -3.99025132 -4.07099402 -4.1370023\n",
      " -4.19193976 -4.23841404 -4.27829851 -4.31295315 -4.3433794  -4.37032784\n",
      " -4.39437204 -4.41595892]\n",
      "[13.9883662  -0.86471035 -2.18793353 -3.00641386 -3.46709618 -3.74789893\n",
      " -3.93327899 -4.06358968 -4.15948351 -4.23233428 -4.28902068 -4.33409487\n",
      " -4.37072114 -4.40113063 -4.42690016 -4.44913795 -4.46857988 -4.4856493\n",
      " -4.50063972 -4.51439404]\n",
      "w_init\n",
      "[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "wmod_init\n",
      "[-2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207\n",
      " -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207\n",
      " -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207\n",
      " -2.99573207 -2.99573207]\n",
      "[-2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207\n",
      " -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207\n",
      " -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207 -2.99573207\n",
      " -2.99573207 -2.99573207]\n",
      "is_scaled\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for key, value in res['model']['prior'].items():\n",
    "    print(key)\n",
    "    print (getattr(gv1.prior, key))\n",
    "    print (value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e9c5586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([-2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207]),\n",
       " 1.0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv1._init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bcd0212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([-2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207,\n",
       "        -2.99573207, -2.99573207, -2.99573207, -2.99573207, -2.99573207]),\n",
       " 0.0014724179775473531)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['model']['_init_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b72f3a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['beta', 'sigma2', 'pi', 'iter', 'varobj', 'intercept', 'data', 'update.order'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cavi['model']['fit'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b152f44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.84962398e-01],\n",
       "       [1.49232105e-02],\n",
       "       [1.99318689e-06],\n",
       "       [1.32140761e-10],\n",
       "       [1.39322102e-12],\n",
       "       [9.39597801e-13],\n",
       "       [6.98103610e-13],\n",
       "       [5.49745844e-13],\n",
       "       [4.61789072e-13],\n",
       "       [4.34008612e-13],\n",
       "       [4.78611181e-13],\n",
       "       [6.12515121e-13],\n",
       "       [8.62172784e-13],\n",
       "       [1.27545270e-12],\n",
       "       [1.94301973e-12],\n",
       "       [3.45200984e-12],\n",
       "       [3.24171641e-10],\n",
       "       [6.78812626e-08],\n",
       "       [4.45916934e-06],\n",
       "       [1.07870741e-04]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cavi['model']['fit']['pi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aca67788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/saikatbanerjee/scratch/work/gradvi-experiments/linreg_indep_gradvi/gradvi_compound/equicorrgauss_1_gradvi_compound_1.pkl'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(_resfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9836083b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/saikatbanerjee/scratch/work/gradvi-experiments/linreg_indep_gradvi/equicorrgauss/equicorrgauss_1.pkl'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(_datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410e77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
