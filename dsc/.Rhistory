b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo((X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s))
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, verbose = FALSE, drop.threshold = 0)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, verbose = FALSE,
drop.threshold = 0, maxiter = 1)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, verbose = FALSE,
drop.threshold = 0, maxiter = 2)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
res$fit$logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, verbose = FALSE,
drop.threshold = 0, maxiter = 3)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, verbose = FALSE,
drop.threshold = 0, maxiter = 10)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, s2init, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, s2init, NULL,
NULL, NULL, FALSE, FALSE, FALSE, NULL,
verbose = FALSE,
drop.threshold = 0, maxiter = 10)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, s2init, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, s2init, NULL,
NULL, NULL, FALSE, FALSE, FALSE, NULL,
verbose = FALSE,
drop.threshold = 0, maxiter = 10)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y, 1.0)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, s2init, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, s2init, NULL,
NULL, NULL, FALSE, FALSE, FALSE, NULL,
verbose = FALSE,
drop.threshold = 0, maxiter = 10)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y, 1.0)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, s2init, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, s2init, NULL,
NULL, NULL, FALSE, FALSE, FALSE, NULL,
verbose = FALSE,
drop.threshold = 0, maxiter = 10)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y, 1.0)
fit_varbvsmix <- function (X, y, k, s2init, winit) {
fit <- varbvs::varbvsmix(X, NULL, y, k, s2init, winit,
NULL, NULL, FALSE, FALSE, FALSE, NULL,
verbose = FALSE,
drop.threshold = 0, maxiter = 10)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
k = 20
wkinit = rep(1/k, k)
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
fit_varbvsmix <- function (X, y, k, s2init, winit) {
fit <- varbvs::varbvsmix(X, NULL, y, k, s2init, winit,
NULL, NULL, FALSE, FALSE, FALSE, NULL,
verbose = FALSE,
drop.threshold = 0, maxiter = 10)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
k = 20
wkinit = rep(1/k, k)
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
res = fit_varbvsmix(X, Y, k, 1.0, wkinit)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
get_posterior <- function(X, y, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, verbose = FALSE,
drop.threshold = 0, maxiter = 1)
return (fit)
}
fit_varbvsmix <- function (X, y, post, maxiter = 10) {
fit <- varbvs::varbvsmix(X, NULL, y, post$sa, post$sigma,
post$w, post$alpha, post$mu,
FALSE, FALSE, FALSE,
verbose = FALSE,
drop.threshold = 0, maxiter = 1)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
init_posterior = get_posterior(X, Y)
res = fit_varbvsmix(X, Y, init_posterior)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
get_posterior <- function(X, y, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, verbose = FALSE,
drop.threshold = 0, maxiter = 1)
return (fit)
}
fit_varbvsmix <- function (X, y, post, maxiter = 2) {
fit <- varbvs::varbvsmix(X, NULL, y, post$sa, post$sigma,
post$w, post$alpha, post$mu,
FALSE, FALSE, FALSE,
verbose = FALSE,
drop.threshold = 0, maxiter = 1)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
init_posterior = get_posterior(X, Y)
res = fit_varbvsmix(X, Y, init_posterior)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
source('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/mr-ash-pen/src/mrashpen/utils/elbo_varbvs.R')
get_posterior <- function(X, y, k = 20) {
fit <- varbvs::varbvsmix(X, NULL, y, k, verbose = FALSE,
drop.threshold = 0, maxiter = 1)
return (fit)
}
fit_varbvsmix <- function (X, y, post, maxiter = 2) {
fit <- varbvs::varbvsmix(X, NULL, y, post$sa, post$sigma,
post$w, post$alpha, post$mu,
FALSE, FALSE, FALSE,
verbose = FALSE,
drop.threshold = 0, maxiter = 1)
b   <- as.vector(coef(fit))
return(list(fit = fit, mu = b[1], beta = b[-1]))
}
set.seed(100)
sd = 1
n = 100
p = n
X = matrix(0,nrow=n,ncol=n)
for(i in 1:n){
X[i:n,i] = 1:(n-i+1)
}
btrue = rep(0,n)
btrue[40] = 8
btrue[41] = -8
Y = X %*% btrue + sd*rnorm(n)
norm = colSums(X^2)
X = t(t(X)/sqrt(norm))
btrue = btrue * sqrt(norm)
plot(Y)
lines(X %*% btrue)
init_posterior = get_posterior(X, Y)
res = fit_varbvsmix(X, Y, init_posterior)
lines(X %*% res$beta + res$mu)
logZ <- ash_elbo(X, Y, res$fit$sa, res$fit$w, res$fit$sigma,
res$fit$alpha, res$fit$mu, res$fit$s)
res$fit$logZ[length(res$fit$logZ)]
logZ
??scale
help("scale")
Z = matrix(1,n,1)
determinant(crossprod(Z),logarithm = TRUE)$modulus[1]/2
crossprod(Z)
determinant(crossprod(Z),logarithm = TRUE)$modulus[1]/2
Z = matrix(1,20000,1)
crossprod(Z)
determinant(crossprod(Z))
DSC_F7EFB530 <- list()
DSC_F7EFB530 <- dscrutils:::load_inputs(c('trial/equicorrgauss/equicorrgauss_10.pkl','trial/mr_ash/equicorrgauss_10_mr_ash_1.rds'), dscrutils:::read_dsc)
setwd('/home/saikat/Documents/work/sparse-regression/mr-ash-penalized/gradvi-experiments/dsc')
DSC_F7EFB530 <- dscrutils:::load_inputs(c('trial/equicorrgauss/equicorrgauss_10.pkl','trial/mr_ash/equicorrgauss_10_mr_ash_1.rds'), dscrutils:::read_dsc)
DSC_REPLICATE <- DSC_F7EFB530$DSC_DEBUG$replicate
DSC_SEED <- ifelse(is.null(DSC_F7EFB530$DSC_DEBUG$seed), 59681840, DSC_F7EFB530$DSC_DEBUG$seed) + 9
DSC_SEED
DSC_F7EFB530
names(DSC_F7EFB530)
beta <- DSC_F7EFB530$beta
beta_est <- DSC_F7EFB530$beta_est
dscrutils:::source_dirs(c('functions'))
TIC_F7EFB530 <- proc.time()
DSC_SEED <- DSC_SEED + DSC_REPLICATE
set.seed(DSC_SEED)
## BEGIN DSC CORE
err <- mse(beta, beta_est)
beta
beta_est
dim(beta)
dim(beta_est)
as.vector(beta_est)
beta - as.vector(beta_est)
beta - beta_est
mean((beta - as.vector(beta_est))^2)
beta
beta[118]
beta_est[118]
